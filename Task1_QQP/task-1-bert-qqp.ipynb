{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013721,"end_time":"2024-04-15T18:36:27.638861","exception":false,"start_time":"2024-04-15T18:36:27.625140","status":"completed"},"tags":[]},"source":["# Fine-Tuning BERT on Quora Question pairs\n","\n","# Introduction\n","\n","In this project, we would use a variety of BERT models (BERT, RoBERTa, ALBERT, DistilBERT, DeBERTa) with the HuggingFace PyTorch library to fine-tune a model to fit the QQP dataset. \n","\n","### BERT (Bidirectional Encoder Representations from Transformers) \n","\n","Original model code [here](https://github.com/google-research/bert) for NLP tasks.\n","\n","BERT consists of 12 Transformer Encoding layers (or 24 for large BERT)\n","\n","\n","# Quora Question Pairs Dataset\n","[Quora](https://www.quora.com/) is a question-and-answer website where questions are asked, answered, followed, and edited by Internet users, either factually or in the form of opinions. Quora was co-founded by former Facebook employees Adam D'Angelo and Charlie Cheever in June 2009. website was made available to the public for the first time on June 21, 2010. Today the website is available in many languages.\n","\n","Over 100 million people visit Quora every month, so it's no surprise that many people ask similarly worded questions. Multiple questions with the same intent can cause seekers to spend more time finding the best answer to their question, and make writers feel they need to answer multiple versions of the same question.\n","\n","The goal is to predict which of the provided pairs of questions contain two questions with the same meaning. The ground truth is the set of labels that have been supplied by human experts. The dataset itself can be downloaded from kaggle: [here](https://www.kaggle.com/c/quora-question-pairs/).\n","\n","## Data fields\n","* id - the id of a training set question pair\n","* qid1, qid2 - unique ids of each question (only available in train.csv)\n","* question1, question2 - the full text of each question\n","* is_duplicate - the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise."]},{"cell_type":"markdown","metadata":{},"source":["To make use of GPU, this notebook should be run on Google Colab or Kaggle. It is highly inadvisable to run this notebook on a local machine as it would take a very long time to train the model. However you can run on local for testing purposes."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:00.255357Z","iopub.status.busy":"2024-04-16T17:49:00.254983Z","iopub.status.idle":"2024-04-16T17:49:00.268066Z","shell.execute_reply":"2024-04-16T17:49:00.267127Z","shell.execute_reply.started":"2024-04-16T17:49:00.255328Z"},"papermill":{"duration":0.034812,"end_time":"2024-04-15T18:36:27.686693","exception":false,"start_time":"2024-04-15T18:36:27.651881","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:00.269857Z","iopub.status.busy":"2024-04-16T17:49:00.269521Z","iopub.status.idle":"2024-04-16T17:49:10.524211Z","shell.execute_reply":"2024-04-16T17:49:10.523356Z","shell.execute_reply.started":"2024-04-16T17:49:00.269832Z"},"papermill":{"duration":1.594531,"end_time":"2024-04-15T18:36:29.294223","exception":false,"start_time":"2024-04-15T18:36:27.699692","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["### Importing all necessary libraries\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from tqdm import tqdm\n","from torch.utils.data import TensorDataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Due to memory and time limit issues, we cannot really use the whole dataset for fine tuning. As a result, we would use a subset of the dataset for training and validation."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:10.525798Z","iopub.status.busy":"2024-04-16T17:49:10.525368Z","iopub.status.idle":"2024-04-16T17:49:10.530027Z","shell.execute_reply":"2024-04-16T17:49:10.529153Z","shell.execute_reply.started":"2024-04-16T17:49:10.525771Z"},"trusted":true},"outputs":[],"source":["num_train_plus_test = 20000 # Later, train and test data ratio is 80:20\n","num_val = 2000 \n","num_unknown_labels_test = 5000\n","# If you want to use all data, set values to None"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:10.532473Z","iopub.status.busy":"2024-04-16T17:49:10.532211Z","iopub.status.idle":"2024-04-16T17:49:10.655144Z","shell.execute_reply":"2024-04-16T17:49:10.654153Z","shell.execute_reply.started":"2024-04-16T17:49:10.532451Z"},"papermill":{"duration":1.979732,"end_time":"2024-04-15T18:36:31.288278","exception":false,"start_time":"2024-04-15T18:36:29.308546","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["10\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>133273</td>\n","      <td>213221</td>\n","      <td>213222</td>\n","      <td>How is the life of a math student? Could you d...</td>\n","      <td>Which level of prepration is enough for the ex...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>402555</td>\n","      <td>536040</td>\n","      <td>536041</td>\n","      <td>How do I control my horny emotions?</td>\n","      <td>How do you control your horniness?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>360472</td>\n","      <td>364011</td>\n","      <td>490273</td>\n","      <td>What causes stool color to change to yellow?</td>\n","      <td>What can cause stool to come out as little balls?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>150662</td>\n","      <td>155721</td>\n","      <td>7256</td>\n","      <td>What can one do after MBBS?</td>\n","      <td>What do i do after my MBBS ?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>183004</td>\n","      <td>279958</td>\n","      <td>279959</td>\n","      <td>Where can I find a power outlet for my laptop ...</td>\n","      <td>Would a second airport in Sydney, Australia be...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id    qid1    qid2                                          question1  \\\n","0  133273  213221  213222  How is the life of a math student? Could you d...   \n","1  402555  536040  536041                How do I control my horny emotions?   \n","2  360472  364011  490273       What causes stool color to change to yellow?   \n","3  150662  155721    7256                        What can one do after MBBS?   \n","4  183004  279958  279959  Where can I find a power outlet for my laptop ...   \n","\n","                                           question2  is_duplicate  \n","0  Which level of prepration is enough for the ex...             0  \n","1                 How do you control your horniness?             1  \n","2  What can cause stool to come out as little balls?             0  \n","3                       What do i do after my MBBS ?             1  \n","4  Would a second airport in Sydney, Australia be...             0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# train_qqp = pd.read_csv(\"/kaggle/input/snlp-project-qqp/train.tsv\", sep=\"\\t\")\n","# dev_qqp = pd.read_csv(\"/kaggle/input/snlp-project-qqp/dev.tsv\", sep=\"\\t\")\n","\n","train_qqp = pd.read_csv(\"/kaggle/input/snlp-project-qqp/train.tsv\", sep=\"\\t\", nrows=num_train_plus_test)\n","dev_qqp = pd.read_csv(\"/kaggle/input/snlp-project-qqp/dev.tsv\", sep=\"\\t\", nrows=num_val)\n","\n","test_unknown_label_qqp = pd.read_csv(\"/kaggle/input/snlp-project-qqp/test.tsv\", sep=\"\\t\", nrows=num_unknown_labels_test)\n","print(len(test_unknown_label_qqp))\n","train_qqp.head()"]},{"cell_type":"markdown","metadata":{},"source":["## BertForSequenceClassification\n","\n","For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task.\n","\n","We’ll be using [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task."]},{"cell_type":"markdown","metadata":{},"source":["### Choosing the BERT variant and the Tokenizer\n","\n","To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary. The tokenization must be performed by the tokenizer included with BERT. This Tokenizer is build upon the WordPiece tokenizer. "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:10.656899Z","iopub.status.busy":"2024-04-16T17:49:10.656509Z","iopub.status.idle":"2024-04-16T17:49:10.718193Z","shell.execute_reply":"2024-04-16T17:49:10.717142Z","shell.execute_reply.started":"2024-04-16T17:49:10.656862Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The current device is cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"The current device is\", device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# PLEASE CHOOSE THE BERT VARIANT MODEL\n","\n","bert_model_name = \"bert-base-uncased\"\n","# bert_model_name = \"roberta-base\"\n","# bert_model_name = \"distilbert-base-uncased\"\n","# bert_model_name = \"albert-base-v2\"\n","# bert_model_name = \"deberta-base\"\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","bert_temp_name = \"microsoft/deberta-base\" if bert_model_name == \"deberta-base\" else bert_model_name\n","\n","tokenizer = AutoTokenizer.from_pretrained(bert_temp_name)\n","bert_classification_model = AutoModelForSequenceClassification.from_pretrained(\n","    pretrained_model_name_or_path=bert_temp_name,\n","    num_labels=2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions=False, # Whether the model returns attentions weights.\n","    output_hidden_states=False, # Whether the model returns all hidden-states.\n",")\n","\n","bert_classification_model = bert_classification_model.to(device)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013,"end_time":"2024-04-15T18:36:31.395538","exception":false,"start_time":"2024-04-15T18:36:31.382538","status":"completed"},"tags":[]},"source":["# Tokenizing\n","To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.065233Z","iopub.status.idle":"2024-04-16T17:49:15.065615Z","shell.execute_reply":"2024-04-16T17:49:15.065445Z","shell.execute_reply.started":"2024-04-16T17:49:15.065430Z"},"papermill":{"duration":0.02437,"end_time":"2024-04-15T18:36:37.527952","exception":false,"start_time":"2024-04-15T18:36:37.503582","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["example_question = train_qqp['question1'][0]\n","\n","print(f\"Original sentence:\\n {example_question}\")\n","\n","example_tokens = tokenizer.tokenize(example_question)\n","\n","print(f\"\\nTokenized by {bert_model_name}:\\n {example_tokens}\")\n","\n","example_tokens_ID = tokenizer.convert_tokens_to_ids(example_tokens)\n","print(f\"\\nToken IDs by {bert_model_name}:\\n {example_tokens_ID}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.014173,"end_time":"2024-04-15T18:36:37.556061","exception":false,"start_time":"2024-04-15T18:36:37.541888","status":"completed"},"tags":[]},"source":["We can combine ``tokenize`` and ``convert_tokens_to_ids`` with the method ``encode``:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.066838Z","iopub.status.idle":"2024-04-16T17:49:15.067224Z","shell.execute_reply":"2024-04-16T17:49:15.067038Z","shell.execute_reply.started":"2024-04-16T17:49:15.067024Z"},"papermill":{"duration":0.023133,"end_time":"2024-04-15T18:36:37.595157","exception":false,"start_time":"2024-04-15T18:36:37.572024","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["example_question = train_qqp['question1'][0]\n","\n","print(f\"Original sentence:\\n {example_question}\")\n","\n","example_tokens_ID = tokenizer.encode(example_question)\n","\n","print(f\"\\nToken IDs by {bert_model_name}:\\n {example_tokens_ID}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.014143,"end_time":"2024-04-15T18:36:37.623786","exception":false,"start_time":"2024-04-15T18:36:37.609643","status":"completed"},"tags":[]},"source":["We can see we got two extra tokens at the start and at the end compared to previous versions. Let's see what they are:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.068323Z","iopub.status.idle":"2024-04-16T17:49:15.068649Z","shell.execute_reply":"2024-04-16T17:49:15.068493Z","shell.execute_reply.started":"2024-04-16T17:49:15.068480Z"},"papermill":{"duration":9.724492,"end_time":"2024-04-15T18:36:47.362514","exception":false,"start_time":"2024-04-15T18:36:37.638022","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["tokenizer.decode(example_tokens_ID)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.022156,"end_time":"2024-04-15T18:36:47.406755","exception":false,"start_time":"2024-04-15T18:36:47.384599","status":"completed"},"tags":[]},"source":["## Special Tokens\n","``[SEP]`` - At the end of every sentence, we need to append the special ``[SEP]`` token.\n","\n","This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (remeber BERT was trained intially to perdict question-answering task).\n","\n","``[CLS]`` - For classification tasks, we must prepend the special ``[CLS]`` token to the beginning of every sentence.\n","\n","This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output.\n","\n","So now let's see how to encode the two questions together:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.070182Z","iopub.status.idle":"2024-04-16T17:49:15.070482Z","shell.execute_reply":"2024-04-16T17:49:15.070347Z","shell.execute_reply.started":"2024-04-16T17:49:15.070335Z"},"papermill":{"duration":0.028661,"end_time":"2024-04-15T18:36:47.458928","exception":false,"start_time":"2024-04-15T18:36:47.430267","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["example_question_1 = train_qqp['question1'][0]\n","example_question_2 = train_qqp['question2'][0]\n","\n","encoded_pair = tokenizer.encode(example_question_1, example_question_2)\n","tokenizer.decode(encoded_pair)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.014418,"end_time":"2024-04-15T18:36:47.488328","exception":false,"start_time":"2024-04-15T18:36:47.473910","status":"completed"},"tags":[]},"source":["## Sentence Length\n","\n","The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n","\n","BERT has two constraints:\n","\n","1. All sentences must be padded or truncated to a single, fixed length.\n","2. The maximum sentence length is 512 tokens.\n","Padding is done with a special ``[PAD]`` token, which is at index 0 in the BERT vocabulary.\n","\n","The maximum length does impact training and evaluation speed.\n","\n","Before we are ready to encode our text, though, we need to decide on a maximum sentence length for padding / truncating to.\n","\n","Let's find the maximum length:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.071460Z","iopub.status.idle":"2024-04-16T17:49:15.071769Z","shell.execute_reply":"2024-04-16T17:49:15.071627Z","shell.execute_reply.started":"2024-04-16T17:49:15.071614Z"},"papermill":{"duration":2.103722,"end_time":"2024-04-15T18:36:49.606625","exception":false,"start_time":"2024-04-15T18:36:47.502903","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["tqdm.pandas()\n","train_qqp[\"question1_length\"] = train_qqp[\"question1\"].progress_apply(lambda question: \n","                                                        len(tokenizer.tokenize(question)))\n","train_qqp[\"question2_length\"] = train_qqp[\"question2\"].progress_apply(lambda question: \n","                                                        len(tokenizer.tokenize(question)))\n","train_qqp[\"joint_length\"] = train_qqp[\"question1_length\"] + train_qqp[\"question2_length\"]\n","\n","MAX_LENGTH = train_qqp[\"joint_length\"].max()\n","\n","print(\"The maximum sentence length is \", MAX_LENGTH)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.016526,"end_time":"2024-04-15T18:36:49.639951","exception":false,"start_time":"2024-04-15T18:36:49.623425","status":"completed"},"tags":[]},"source":["### Now we construct the training, validation, testing dataset with known labels and testing dataset with unknown labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.073935Z","iopub.status.idle":"2024-04-16T17:49:15.074294Z","shell.execute_reply":"2024-04-16T17:49:15.074147Z","shell.execute_reply.started":"2024-04-16T17:49:15.074128Z"},"papermill":{"duration":0.032564,"end_time":"2024-04-15T18:36:49.689023","exception":false,"start_time":"2024-04-15T18:36:49.656459","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["X_train, X_test_known_labels, y_train, y_test_known_labels = train_test_split(train_qqp[[\"question1\", \"question2\"]], \n","                                                    train_qqp[\"is_duplicate\"], test_size=0.2, random_state=42)\n","X_val = dev_qqp[[\"question1\", \"question2\"]]\n","y_val = dev_qqp[\"is_duplicate\"]\n","\n","X_test_unknown_labels = test_unknown_label_qqp[[\"question1\", \"question2\"]]"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.016289,"end_time":"2024-04-15T18:36:49.721709","exception":false,"start_time":"2024-04-15T18:36:49.705420","status":"completed"},"tags":[]},"source":["# Tokenize dataset and create Dataloader\n","\n","Now we’re ready to perform the real tokenization.\n","\n","The tokenizer.encode_plus function combines multiple steps for us:\n","\n","1. Split the sentence into tokens.\n","2. Add the special ``[CLS]`` and ``[SEP]`` tokens.\n","3. Map the tokens to their IDs.\n","4. Pad or truncate all sentences to the same length.\n","5. Create the attention masks which explicitly differentiate real tokens from ``[PAD]`` tokens.\n","\n","Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.075563Z","iopub.status.idle":"2024-04-16T17:49:15.075901Z","shell.execute_reply":"2024-04-16T17:49:15.075752Z","shell.execute_reply.started":"2024-04-16T17:49:15.075738Z"},"papermill":{"duration":0.101843,"end_time":"2024-04-15T18:36:49.840093","exception":false,"start_time":"2024-04-15T18:36:49.738250","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["MAX_LENGTH = 327\n","\n","tokenizer.encode_plus(X_train.iloc[0][\"question1\"], \n","                      X_train.iloc[0][\"question2\"], \n","                      max_length=MAX_LENGTH, \n","                      padding='max_length', \n","                      return_attention_mask=True, \n","                      return_tensors='pt', \n","                      truncation=True)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.016895,"end_time":"2024-04-15T18:36:49.873851","exception":false,"start_time":"2024-04-15T18:36:49.856956","status":"completed"},"tags":[]},"source":["So what we got:\n","\n","1. input_ids - Token ids padded with 0 at the end.\n","2. token_type_ids - This array indicates bert what is the first sentence and what is the seconds. In case of classification of only one sentance this array is redundant.\n","3. attention_mask - The “Attention Mask” is simply an array of 1s and 0s indicating which tokens are padding and which aren’t. This mask tells the “Self-Attention” mechanism in BERT not to incorporate these ``[PAD]`` tokens into its interpretation of the sentence.\n","\n","All the array are in the size of ``max_length``."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.077271Z","iopub.status.idle":"2024-04-16T17:49:15.077758Z","shell.execute_reply":"2024-04-16T17:49:15.077568Z","shell.execute_reply.started":"2024-04-16T17:49:15.077544Z"},"papermill":{"duration":0.028634,"end_time":"2024-04-15T18:36:49.919151","exception":false,"start_time":"2024-04-15T18:36:49.890517","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def convert_to_dataset_torch(features, labels):\n","    input_ids = []\n","    attention_masks = []\n","    token_type_ids = []\n","    for _, row in tqdm(features.iterrows(), total=features.shape[0]):\n","        encoded_dict = tokenizer.encode_plus(row[\"question1\"], \n","                                             row[\"question2\"], \n","                                             padding='max_length', \n","                                             return_attention_mask=True, \n","                                             return_tensors='pt', \n","                                             truncation=True)\n","        # print(encoded_dict.keys())\n","        \n","        # Add the encoded sentences to the list.\n","        input_ids.append(encoded_dict['input_ids'])\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks.append(encoded_dict['attention_mask'])\n","        \n","        if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","            token_type_ids.append(encoded_dict[\"token_type_ids\"])\n","        \n","    # Convert the lists into tensors.\n","    if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","\n","        input_ids = torch.cat(input_ids, dim=0)\n","        token_type_ids = torch.cat(token_type_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","        labels = torch.tensor(labels.values)\n","        \n","        print(\"Shape of input_ids is\", input_ids.shape)\n","        print(\"Shape of token_type_ids is\", token_type_ids.shape)\n","        print(\"Shape of attention_masks is\", attention_masks.shape)\n","        print(\"Shape of labels is\", labels.shape)\n","        \n","        return TensorDataset(input_ids, attention_masks, token_type_ids, labels)\n","    \n","    elif bert_model_name in [\"roberta-base\", \"distilbert-base-uncased\"]:\n","        # roberta does not have token_type_ids\n","        input_ids = torch.cat(input_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","        labels = torch.tensor(labels.values)\n","        \n","        print(\"Shape of input_ids is\", input_ids.shape)\n","        print(\"Shape of attention_masks is\", attention_masks.shape)\n","        print(\"Shape of labels is\", labels.shape)\n","        \n","        return TensorDataset(input_ids, attention_masks, labels)\n","    "]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.016871,"end_time":"2024-04-15T18:36:49.953559","exception":false,"start_time":"2024-04-15T18:36:49.936688","status":"completed"},"tags":[]},"source":["We’ll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.078914Z","iopub.status.idle":"2024-04-16T17:49:15.079298Z","shell.execute_reply":"2024-04-16T17:49:15.079127Z","shell.execute_reply.started":"2024-04-16T17:49:15.079091Z"},"papermill":{"duration":8.287055,"end_time":"2024-04-15T18:36:58.257606","exception":false,"start_time":"2024-04-15T18:36:49.970551","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_tensor = convert_to_dataset_torch(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.081080Z","iopub.status.idle":"2024-04-16T17:49:15.081450Z","shell.execute_reply":"2024-04-16T17:49:15.081292Z","shell.execute_reply.started":"2024-04-16T17:49:15.081279Z"},"papermill":{"duration":2.021747,"end_time":"2024-04-15T18:37:00.303924","exception":false,"start_time":"2024-04-15T18:36:58.282177","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["val_tensor = convert_to_dataset_torch(X_val, y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.082864Z","iopub.status.idle":"2024-04-16T17:49:15.083266Z","shell.execute_reply":"2024-04-16T17:49:15.083074Z","shell.execute_reply.started":"2024-04-16T17:49:15.083060Z"},"papermill":{"duration":0.035939,"end_time":"2024-04-15T18:37:00.365433","exception":false,"start_time":"2024-04-15T18:37:00.329494","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import multiprocessing\n","\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it here.\n","\n","batch_size = 5\n","\n","core_number = multiprocessing.cpu_count()\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_tensor,  # The training samples.\n","            sampler = RandomSampler(train_tensor), # Select batches randomly\n","            batch_size = batch_size, # Trains with this batch size.\n","            num_workers = core_number\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","val_dataloader = DataLoader(\n","            val_tensor, # The validation samples.\n","            sampler = SequentialSampler(val_tensor), # Pull out batches sequentially.\n","            batch_size = batch_size, # Evaluate with this batch size.\n","            num_workers = core_number\n","        )"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.025836,"end_time":"2024-04-15T18:37:05.155030","exception":false,"start_time":"2024-04-15T18:37:05.129194","status":"completed"},"tags":[]},"source":["# Training Loop\n","Helper function for formatting elapsed times as ``hh:mm:ss``:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.086449Z","iopub.status.idle":"2024-04-16T17:49:15.086813Z","shell.execute_reply":"2024-04-16T17:49:15.086643Z","shell.execute_reply.started":"2024-04-16T17:49:15.086629Z"},"papermill":{"duration":0.033386,"end_time":"2024-04-15T18:37:05.215284","exception":false,"start_time":"2024-04-15T18:37:05.181898","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.025281,"end_time":"2024-04-15T18:37:05.266175","exception":false,"start_time":"2024-04-15T18:37:05.240894","status":"completed"},"tags":[]},"source":["### This function trains the batches from the train_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.088478Z","iopub.status.idle":"2024-04-16T17:49:15.088846Z","shell.execute_reply":"2024-04-16T17:49:15.088671Z","shell.execute_reply.started":"2024-04-16T17:49:15.088657Z"},"papermill":{"duration":0.036185,"end_time":"2024-04-15T18:37:05.328085","exception":false,"start_time":"2024-04-15T18:37:05.291900","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def train_batch(epoch, bert_classification_model, train_dataloader, optimizer, scheduler, metric):\n","    \n","    total_train_loss = 0\n","    total_train_accuracy = 0\n","    \n","    for batch in tqdm(train_dataloader, desc=f\"Training epoch: {epoch}\", unit=\"batch\"):\n","        \n","        if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","\n","            # Unpack batch from dataloader.\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            token_type_ids = batch[2].to(device)\n","            labels = batch[3].to(device)\n","            \n","            bert_classification_model.zero_grad()\n","            \n","            # Forward pass\n","            outputs = bert_classification_model(input_ids, \n","                                token_type_ids=token_type_ids, \n","                                attention_mask=attention_masks, \n","                                labels=labels)\n","            \n","        elif bert_model_name in [\"roberta-base\", \"distilbert-base-uncased\"]:\n","            # Unpack batch from dataloader.\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            labels = batch[2].to(device)\n","            \n","            bert_classification_model.zero_grad()\n","            \n","            # Forward pass\n","            outputs = bert_classification_model(input_ids, \n","                                attention_mask=attention_masks, \n","                                labels=labels)\n","            \n","        loss = outputs.loss\n","        logits = outputs.logits\n","\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(bert_classification_model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        y_pred = np.argmax(logits.cpu().detach().numpy(), axis=1).flatten()\n","        \n","        total_train_accuracy += metric(labels.cpu(), y_pred)\n","\n","    return total_train_loss, total_train_accuracy"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.024768,"end_time":"2024-04-15T18:37:05.379318","exception":false,"start_time":"2024-04-15T18:37:05.354550","status":"completed"},"tags":[]},"source":["### This function validates the batches from the val_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.089914Z","iopub.status.idle":"2024-04-16T17:49:15.090265Z","shell.execute_reply":"2024-04-16T17:49:15.090090Z","shell.execute_reply.started":"2024-04-16T17:49:15.090078Z"},"papermill":{"duration":0.039203,"end_time":"2024-04-15T18:37:05.445136","exception":false,"start_time":"2024-04-15T18:37:05.405933","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def val_batch(epoch, bert_classification_model, val_dataloader, metric):\n","    total_val_loss = 0\n","    total_val_accuracy = 0\n","    predicted_logits , predicted_labels = [], []\n","    \n","    for batch in tqdm(val_dataloader, desc=f\"Validating epoch: {epoch}\", unit=\"batch\"):\n","        # Unpack batch from dataloader.\n","        \n","        if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            token_type_ids = batch[2].to(device)\n","            labels = batch[3].to(device)\n","\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions.\n","                outputs = bert_classification_model(input_ids, \n","                                    token_type_ids=token_type_ids, \n","                                    attention_mask=attention_masks,\n","                                    labels=labels)\n","                loss = outputs.loss\n","                logits = outputs.logits\n","                \n","        elif bert_model_name in [\"roberta-base\", \"distilbert-base-uncased\"]:\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            labels = batch[2].to(device)\n","\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions.\n","                outputs = bert_classification_model(input_ids, \n","                                    attention_mask=attention_masks,\n","                                    labels=labels)\n","                loss = outputs.loss\n","                logits = outputs.logits\n","            \n","        total_val_loss += loss.item()\n","        \n","        y_pred = np.argmax(logits.cpu().detach().numpy(), axis=1).flatten()\n","        \n","        total_val_accuracy += metric(labels.cpu(), y_pred)\n","        \n","        predicted_logits.extend(logits.cpu().detach().numpy().tolist())\n","        predicted_labels.extend(y_pred.tolist())\n","    \n","    return total_val_loss, total_val_accuracy, predicted_logits, predicted_labels"]},{"cell_type":"markdown","metadata":{},"source":["### This function predicts the classes of the batches from the test_dataloader. Now the test_dataloader only contains X_test without y_test (which is None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.091442Z","iopub.status.idle":"2024-04-16T17:49:15.091765Z","shell.execute_reply":"2024-04-16T17:49:15.091607Z","shell.execute_reply.started":"2024-04-16T17:49:15.091594Z"},"trusted":true},"outputs":[],"source":["def predict_batch(bert_classification_model, predict_dataloader):\n","    \n","    predicted_logits , predicted_labels = [], []\n","    \n","    for batch in tqdm(predict_dataloader, desc=f\"Predicting\", unit=\"batch\"):\n","        # Unpack batch from dataloader.\n","        \n","        if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            token_type_ids = batch[2].to(device)\n","\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions.\n","                outputs = bert_classification_model(input_ids, \n","                                    token_type_ids=token_type_ids, \n","                                    attention_mask=attention_masks)\n","                logits = outputs.logits\n","                \n","        elif bert_model_name in [\"roberta-base\", \"distilbert-base-uncased\"]:\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions.\n","                outputs = bert_classification_model(input_ids, \n","                                    attention_mask=attention_masks)\n","                logits = outputs.logits\n","            \n","        y_pred = np.argmax(logits.cpu().detach().numpy(), axis=1).flatten()\n","                \n","        predicted_logits.extend(logits.cpu().detach().numpy().tolist())\n","        predicted_labels.extend(y_pred.tolist())\n","    \n","    return predicted_logits, predicted_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.093424Z","iopub.status.idle":"2024-04-16T17:49:15.093733Z","shell.execute_reply":"2024-04-16T17:49:15.093595Z","shell.execute_reply.started":"2024-04-16T17:49:15.093583Z"},"papermill":{"duration":0.040053,"end_time":"2024-04-15T18:37:05.566326","exception":false,"start_time":"2024-04-15T18:37:05.526273","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import random\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","\n","def fine_tuning_pretrained_model(epochs, bert_classification_model, \n","                                 train_dataloader, \n","                                 val_dataloader, \n","                                 optimizer, \n","                                 scheduler,\n","                                 metric\n","                                 ):\n","    \n","    fine_tuning_statistics = []\n","    \n","    for epoch in range(1, epochs + 1):\n","\n","        #################\n","        # TRAINING PART #\n","        #################\n","\n","        t_begin_train = time.time()\n","        \n","        bert_classification_model.train()\n","        \n","        total_train_loss, total_train_accuracy = train_batch(epoch,\n","                                       bert_classification_model,\n","                                       train_dataloader,\n","                                       optimizer,\n","                                       scheduler,\n","                                       metric\n","                                       )\n","        \n","        # Calculate the average training loss for all batches.\n","        average_train_loss = total_train_loss / len(train_dataloader)\n","        print(f\"  Average training loss: {average_train_loss}\")\n","\n","        # Calculate the average training accuracy for all batches.\n","        average_train_accuracy = total_train_accuracy / len(train_dataloader)\n","        print(f\"  Average training accuracy: {average_train_accuracy}\")\n","        \n","        t_end_train = time.time()\n","\n","        training_time = format_time(t_end_train - t_begin_train)\n","        print(f\"  Training time took: {training_time}\")\n","        \n","        ###################\n","        # VALIDATING PART #\n","        ###################\n","\n","        t_begin_val = time.time()\n","        \n","        bert_classification_model.eval()\n","        \n","        total_val_loss, total_val_accuracy,\\\n","        predicted_logits, predicted_labels = val_batch(epoch, \n","                                                        bert_classification_model,\n","                                                        val_dataloader,\n","                                                        metric)\n","        \n","        # Calculate the average validation loss for all batches.\n","        average_val_loss = total_val_loss / len(val_dataloader)\n","        print(f\"  Average validation loss: {average_val_loss}\")\n","\n","        # Calculate the average validation accuracy for all batches.\n","        average_val_accuracy = total_val_accuracy / len(val_dataloader)\n","        print(f\"  Average validation accuracy: {average_val_accuracy}\")\n","    \n","        t_end_val = time.time()\n","\n","        validation_time = format_time(t_end_val - t_begin_val)\n","        print(f\"  Validation time took: {validation_time}\")\n","    \n","        # Record all statistics from this epoch.\n","        fine_tuning_statistics.append(\n","            {\n","                'epoch': epoch,\n","                'train_loss': average_train_loss,\n","                'train_accuracy': average_train_accuracy,\n","                'train_time': training_time,\n","                'val_loss': average_val_loss,\n","                'val_accuracy': average_val_accuracy,\n","                'val_time': validation_time\n","            }\n","        )\n","        \n","\n","    print(\"\")\n","    print(\"Training complete!\")\n","\n","    return fine_tuning_statistics"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.027716,"end_time":"2024-04-15T18:37:05.620847","exception":false,"start_time":"2024-04-15T18:37:05.593131","status":"completed"},"tags":[]},"source":["# Optimizer & Learning Rate Scheduler\n","Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n","\n","For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n","\n","* Batch size: 16, 32\n","* Learning rate (Adam): 5e-5, 3e-5, 2e-5\n","* Number of epochs: 2, 3, 4\n","\n","I chose:\n","* Batch size: 10 (due to memory limit of Kaggle)\n","* Learning rate: 2e-5\n","* Number of epochs: 4\n","\n","We’re ready to kick off the training:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.095227Z","iopub.status.idle":"2024-04-16T17:49:15.095558Z","shell.execute_reply":"2024-04-16T17:49:15.095412Z","shell.execute_reply.started":"2024-04-16T17:49:15.095399Z"},"papermill":{"duration":2970.860026,"end_time":"2024-04-15T19:26:36.507068","exception":false,"start_time":"2024-04-15T18:37:05.647042","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from torch.optim import AdamW\n","from sklearn.metrics import accuracy_score\n","\n","adamw_optimizer = AdamW(bert_classification_model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(adamw_optimizer, \n","                                            num_warmup_steps = 0, \n","                                            num_training_steps = total_steps)\n","\n","# Finally, we start to train the model\n","fine_tuning_statistics = fine_tuning_pretrained_model(\n","    epochs,\n","    bert_classification_model,\n","    train_dataloader,\n","    val_dataloader,\n","    adamw_optimizer,\n","    scheduler,\n","    accuracy_score)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.388697,"end_time":"2024-04-15T19:26:37.242050","exception":false,"start_time":"2024-04-15T19:26:36.853353","status":"completed"},"tags":[]},"source":["### Let’s view the summary of the training process. First we create a folder to save the results for the BERT variant"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.096916Z","iopub.status.idle":"2024-04-16T17:49:15.097264Z","shell.execute_reply":"2024-04-16T17:49:15.097082Z","shell.execute_reply.started":"2024-04-16T17:49:15.097070Z"},"trusted":true},"outputs":[],"source":["if not os.path.exists(f\"{bert_model_name}\"):\n","    os.makedirs(f\"{bert_model_name}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.098957Z","iopub.status.idle":"2024-04-16T17:49:15.099436Z","shell.execute_reply":"2024-04-16T17:49:15.099221Z","shell.execute_reply.started":"2024-04-16T17:49:15.099203Z"},"papermill":{"duration":0.360694,"end_time":"2024-04-15T19:26:37.941464","exception":false,"start_time":"2024-04-15T19:26:37.580770","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["df_stats = pd.DataFrame(fine_tuning_statistics).set_index('epoch')\n","# Saving the fine_tuning_statistics\n","df_stats.to_csv(f\"{bert_model_name}/fine_tuning_statistics.csv\")\n","df_stats"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.100729Z","iopub.status.idle":"2024-04-16T17:49:15.101030Z","shell.execute_reply":"2024-04-16T17:49:15.100894Z","shell.execute_reply.started":"2024-04-16T17:49:15.100882Z"},"papermill":{"duration":0.656377,"end_time":"2024-04-15T19:26:38.936759","exception":false,"start_time":"2024-04-15T19:26:38.280382","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from matplotlib import pyplot\n","\n","%matplotlib inline\n","\n","pyplot.plot(df_stats['train_loss'], 'b-o', label=\"training\")\n","pyplot.plot(df_stats['val_loss'], 'g-o', label=\"validation\")\n","pyplot.title(f\"{bert_model_name}: training & validation loss\", fontsize=15)\n","pyplot.xlabel(\"Epoch\", fontsize=14)\n","pyplot.ylabel(\"Loss\", fontsize=14)\n","pyplot.legend(frameon=False, fontsize=14)\n","pyplot.xticks(df_stats.index.values.tolist(), fontsize=12)\n","pyplot.yticks(fontsize=12)\n","pyplot.savefig(f\"{bert_model_name}/train_val_loss_plot.png\")\n","pyplot.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.101922Z","iopub.status.idle":"2024-04-16T17:49:15.102260Z","shell.execute_reply":"2024-04-16T17:49:15.102083Z","shell.execute_reply.started":"2024-04-16T17:49:15.102071Z"},"trusted":true},"outputs":[],"source":["from matplotlib import pyplot\n","\n","%matplotlib inline\n","\n","pyplot.plot(df_stats['train_accuracy'], 'b-o', label=\"training\")\n","pyplot.plot(df_stats['val_accuracy'], 'g-o', label=\"validation\")\n","pyplot.title(f\"{bert_model_name}: training & validation accuracy\", fontsize=15)\n","pyplot.xlabel(\"Epoch\", fontsize=14)\n","pyplot.ylabel(\"Loss\", fontsize=14)\n","pyplot.legend(frameon=False, fontsize=14)\n","pyplot.xticks(df_stats.index.values.tolist(), fontsize=12)\n","pyplot.yticks(fontsize=12)\n","pyplot.savefig(f\"{bert_model_name}/train_val_accuracy_plot.png\")\n","pyplot.show()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.384476,"end_time":"2024-04-15T19:26:39.668675","exception":false,"start_time":"2024-04-15T19:26:39.284199","status":"completed"},"tags":[]},"source":["## Performance on test set and prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.103474Z","iopub.status.idle":"2024-04-16T17:49:15.103773Z","shell.execute_reply":"2024-04-16T17:49:15.103636Z","shell.execute_reply.started":"2024-04-16T17:49:15.103623Z"},"papermill":{"duration":2.355805,"end_time":"2024-04-15T19:26:42.364086","exception":false,"start_time":"2024-04-15T19:26:40.008281","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["print(type(y_test_known_labels))\n","test_tensor_known_labels = convert_to_dataset_torch(X_test_known_labels, y_test_known_labels)\n","test_dataloader = DataLoader(test_tensor_known_labels, \n","                             sampler=SequentialSampler(test_tensor_known_labels), \n","                             batch_size=batch_size)\n","\n","#print(len(X_test_unknown_labels))\n","#features_tensor = torch.tensor(X_test_unknown_labels.to_numpy(), dtype=torch.float32)\n","#print(features_tensor.shape)\n","\n","# Create dummy labels tensor\n","\n","dummy_labels_series = pd.Series([-1] * len(X_test_unknown_labels))\n","# print(X_test_unknown_labels.shape)\n","test_tensor_unknown_labels = convert_to_dataset_torch(X_test_unknown_labels, dummy_labels_series)\n","predict_dataloader = DataLoader(test_tensor_unknown_labels, \n","                             sampler=SequentialSampler(test_tensor_unknown_labels), \n","                             batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.362368,"end_time":"2024-04-15T19:26:43.095895","exception":false,"start_time":"2024-04-15T19:26:42.733527","status":"completed"},"tags":[]},"source":["## Evaluate on the test set with known labels\n","With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set with known labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.104733Z","iopub.status.idle":"2024-04-16T17:49:15.105030Z","shell.execute_reply":"2024-04-16T17:49:15.104894Z","shell.execute_reply.started":"2024-04-16T17:49:15.104883Z"},"papermill":{"duration":61.396734,"end_time":"2024-04-15T19:27:44.840416","exception":false,"start_time":"2024-04-15T19:26:43.443682","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["bert_classification_model.eval()\n","\n","total_val_loss, total_val_accuracy,\\\n","predicted_logits_val, predicted_labels_val = val_batch(None, bert_classification_model, \n","                                               test_dataloader, accuracy_score)"]},{"cell_type":"markdown","metadata":{},"source":["## Making prediction on the test set with unknown labels\n","\n","With the predict set prepared, we can apply our fine-tuned model to generate predictions on the test set with unknown labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.106532Z","iopub.status.idle":"2024-04-16T17:49:15.106896Z","shell.execute_reply":"2024-04-16T17:49:15.106741Z","shell.execute_reply.started":"2024-04-16T17:49:15.106727Z"},"trusted":true},"outputs":[],"source":["bert_classification_model.eval()\n","\n","predicted_logits_test, predicted_labels_test = predict_batch(bert_classification_model, \n","                                                   predict_dataloader)"]},{"cell_type":"markdown","metadata":{},"source":["### We construct the testing result with corresponding truth labels and predicted labels by the fine-tuned BERT model. This testing data is part of the training data (train.tsv)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.108421Z","iopub.status.idle":"2024-04-16T17:49:15.108743Z","shell.execute_reply":"2024-04-16T17:49:15.108600Z","shell.execute_reply.started":"2024-04-16T17:49:15.108586Z"},"trusted":true},"outputs":[],"source":["testing_results_known_labels = pd.DataFrame()\n","testing_results_known_labels[\"question1\"] = X_test_known_labels[\"question1\"]\n","testing_results_known_labels[\"question2\"] = X_test_known_labels[\"question2\"]\n","testing_results_known_labels[\"true_is_duplicate\"] = y_test_known_labels\n","testing_results_known_labels[\"predicted_is_duplicate\"] = predicted_labels_val\n","testing_results_known_labels.head()"]},{"cell_type":"markdown","metadata":{},"source":["### We construct the testing result with no known labels (the test.tsv file) with the predicted labels by the fine-tuned BERT model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.112288Z","iopub.status.idle":"2024-04-16T17:49:15.112652Z","shell.execute_reply":"2024-04-16T17:49:15.112499Z","shell.execute_reply.started":"2024-04-16T17:49:15.112485Z"},"trusted":true},"outputs":[],"source":["testing_results_unknown_labels = pd.DataFrame()\n","testing_results_unknown_labels[\"question1\"] = X_test_unknown_labels[\"question1\"]\n","testing_results_unknown_labels[\"question2\"] = X_test_unknown_labels[\"question2\"]\n","testing_results_unknown_labels[\"predicted_is_duplicate\"] = predicted_labels_test\n","testing_results_unknown_labels.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Saving testing results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.114297Z","iopub.status.idle":"2024-04-16T17:49:15.114638Z","shell.execute_reply":"2024-04-16T17:49:15.114491Z","shell.execute_reply.started":"2024-04-16T17:49:15.114477Z"},"trusted":true},"outputs":[],"source":["testing_results_known_labels.to_csv(f\"{bert_model_name}/testing_results_known_labels.csv\", index=False)\n","testing_results_unknown_labels.to_csv(f\"{bert_model_name}/testing_results_unknown_labels.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.116125Z","iopub.status.idle":"2024-04-16T17:49:15.116589Z","shell.execute_reply":"2024-04-16T17:49:15.116362Z","shell.execute_reply.started":"2024-04-16T17:49:15.116344Z"},"papermill":{"duration":14.174761,"end_time":"2024-04-15T19:28:00.100426","exception":false,"start_time":"2024-04-15T19:27:45.925665","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!pip install data-science-utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.118284Z","iopub.status.idle":"2024-04-16T17:49:15.118750Z","shell.execute_reply":"2024-04-16T17:49:15.118531Z","shell.execute_reply.started":"2024-04-16T17:49:15.118512Z"},"papermill":{"duration":1.267661,"end_time":"2024-04-15T19:28:01.759154","exception":false,"start_time":"2024-04-15T19:28:00.491493","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from ds_utils.metrics import plot_confusion_matrix\n","\n","plot_confusion_matrix(y_test_known_labels, predicted_labels_val, [1, 0])\n","pyplot.savefig(f\"{bert_model_name}/confusion_matrix.png\")\n","pyplot.show()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.375146,"end_time":"2024-04-15T19:28:02.560249","exception":false,"start_time":"2024-04-15T19:28:02.185103","status":"completed"},"tags":[]},"source":["# Saving the fine-tuned model\n","First let's save our model with the method ``save_pretrained``, then save our tokenizer with ``save_pretrained``.\n","\n","**Pay Attension**: tokenizer's ``save_pretrained`` need to get the path to save as a string.\n","\n","In reality, it is not required to run this cell. Obtaining the results is already enough. The saved model would be extremely heavy, and there are already fine tuned BERT models on HuggingFace"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.120278Z","iopub.status.idle":"2024-04-16T17:49:15.120733Z","shell.execute_reply":"2024-04-16T17:49:15.120522Z","shell.execute_reply.started":"2024-04-16T17:49:15.120503Z"},"papermill":{"duration":1.28376,"end_time":"2024-04-15T19:28:04.217720","exception":false,"start_time":"2024-04-15T19:28:02.933960","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from pathlib import Path\n","\n","output_dir = Path(\"__file__\").parents[0].absolute().joinpath(f\"{bert_model_name}/model_save\")\n","output_dir.mkdir(exist_ok=True)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","\n","# model_to_save = bert_classification_model.module if hasattr(bert_classification_model, 'module') else bert_classification_model  # Take care of distributed/parallel training\n","# model_to_save.save_pretrained(output_dir)\n","# tokenizer.save_pretrained(str(output_dir.absolute()))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4801042,"sourceId":8124328,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"papermill":{"default_parameters":{},"duration":3102.798711,"end_time":"2024-04-15T19:28:07.632117","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-15T18:36:24.833406","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"07f63ac385e245e69643261fa301d1e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a779e03f4ef4dfb9dc2d08b9d97ffa6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10ec51a0d39644c2bde1c044f4b0ebcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10fb04b92e174f849b69c56d203668ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a573658ed14c48d3a6a866cae319ac6c","IPY_MODEL_475ddaa2422245abb188229f13289e3b","IPY_MODEL_79acbae3e21e4376b30795092f52e8f2"],"layout":"IPY_MODEL_a13478a623724f66b1a14660d3ee9b4c"}},"128ec8e6c5d44978a2e9f175388e2f29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cb8161b6d734b6a8a15af28275ef483":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f84540677f046efa31d6d90bb798393":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21e35c6ec57b4193bf50aecf1f702ac0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"252f4288a4c84d728c963178e69ad1f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74ed9df4556f4ce7a213050c48d7c210","IPY_MODEL_bdb76a9b14d2447d942fd2620266531f","IPY_MODEL_42fd17a164ad42feb46d98ca2d4e9c71"],"layout":"IPY_MODEL_dc1cc80bd35b4d5dae4679b8825368f6"}},"2c93f0851b684e0494d3c01044488537":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3683cb285f2b4634ae9fd869432cc86c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"387cac20b6294c009cf4f1f1d9440597":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed790f27239244649065667c37f56eb8","placeholder":"​","style":"IPY_MODEL_3c973380efdc46cd8415b5809cfa7f77","value":"model.safetensors: 100%"}},"3c973380efdc46cd8415b5809cfa7f77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42fd17a164ad42feb46d98ca2d4e9c71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_740886dea1fa48a9a06c17dadf3b6fbd","placeholder":"​","style":"IPY_MODEL_c63272069adc4b46a5bcc989ea18c0e0","value":" 232k/232k [00:00&lt;00:00, 5.70MB/s]"}},"475ddaa2422245abb188229f13289e3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b6601cf17dd46be9c10f6e87a1144aa","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_128ec8e6c5d44978a2e9f175388e2f29","value":466062}},"48b48c0a4e764642a4baa3380c8a9a8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ab51461176848458df8f7aa1c18a9e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21e35c6ec57b4193bf50aecf1f702ac0","placeholder":"​","style":"IPY_MODEL_3683cb285f2b4634ae9fd869432cc86c","value":" 48.0/48.0 [00:00&lt;00:00, 3.54kB/s]"}},"5519dd8cd22445109116713dc5314117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55bbfc2baca942e7837c0d480dd8d6de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58395f0c6881462ab960c9756ad249c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5eb0fe60340413fb5161245a1a5096f","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5519dd8cd22445109116713dc5314117","value":48}},"5b6601cf17dd46be9c10f6e87a1144aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e3c797bc7a4829b0c8b2bec78b05bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"740886dea1fa48a9a06c17dadf3b6fbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74ed9df4556f4ce7a213050c48d7c210":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db671e831e74462a2edde8154c087b8","placeholder":"​","style":"IPY_MODEL_0a779e03f4ef4dfb9dc2d08b9d97ffa6","value":"vocab.txt: 100%"}},"79acbae3e21e4376b30795092f52e8f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c66320e4daa1422fb28121fd94b5668a","placeholder":"​","style":"IPY_MODEL_1f84540677f046efa31d6d90bb798393","value":" 466k/466k [00:00&lt;00:00, 22.4MB/s]"}},"7db671e831e74462a2edde8154c087b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b67ebaa10884aff89c4aafe648550d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb019431ea60438095147927a0935bbb","placeholder":"​","style":"IPY_MODEL_b7235bc7b1ce45658a992e230c300b7a","value":"tokenizer_config.json: 100%"}},"8f4c677ab169495581975dd1851e0edf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cb8161b6d734b6a8a15af28275ef483","placeholder":"​","style":"IPY_MODEL_70e3c797bc7a4829b0c8b2bec78b05bd","value":" 570/570 [00:00&lt;00:00, 47.9kB/s]"}},"8f4e34afb9cf4030977b9940bfa279e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db400aad92ad449eb08c29ad43c38774","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c814b40c830c4f61ba82b1da0edd6c05","value":440449768}},"98bce00eebcd4bcdba25e51e41dfdb15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9db693f375a0422f9d84b6e2fb9b63f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb031d76dbc14c88975b16a64c1cddea","placeholder":"​","style":"IPY_MODEL_2c93f0851b684e0494d3c01044488537","value":"config.json: 100%"}},"a13478a623724f66b1a14660d3ee9b4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4c828db3926417fa793da999dd17166":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a573658ed14c48d3a6a866cae319ac6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07f63ac385e245e69643261fa301d1e5","placeholder":"​","style":"IPY_MODEL_10ec51a0d39644c2bde1c044f4b0ebcf","value":"tokenizer.json: 100%"}},"a8b9dc282be24106806e603524f0e957":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2cb094195dd4c88b55eab4e7b32d99b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b67ebaa10884aff89c4aafe648550d8","IPY_MODEL_58395f0c6881462ab960c9756ad249c2","IPY_MODEL_4ab51461176848458df8f7aa1c18a9e7"],"layout":"IPY_MODEL_dc391f34db0e43ae96f1bc5079279edd"}},"b5ad6af9c7fb46e4a33bc078155a1fea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5ff972a4a0d452286e70738ffdf5ab6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9db693f375a0422f9d84b6e2fb9b63f1","IPY_MODEL_c6894eaf5ded4f9ab773f2b108874f37","IPY_MODEL_8f4c677ab169495581975dd1851e0edf"],"layout":"IPY_MODEL_48b48c0a4e764642a4baa3380c8a9a8e"}},"b7235bc7b1ce45658a992e230c300b7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdb76a9b14d2447d942fd2620266531f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6cac9b8ec2540d6a4acfead90020e91","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98bce00eebcd4bcdba25e51e41dfdb15","value":231508}},"c63272069adc4b46a5bcc989ea18c0e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c66320e4daa1422fb28121fd94b5668a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6894eaf5ded4f9ab773f2b108874f37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5ad6af9c7fb46e4a33bc078155a1fea","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef619ee29eca42038cd174dac32da185","value":570}},"c814b40c830c4f61ba82b1da0edd6c05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb031d76dbc14c88975b16a64c1cddea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7be6f8f41ca4f36a0e5beb3e49a1a1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b9dc282be24106806e603524f0e957","placeholder":"​","style":"IPY_MODEL_55bbfc2baca942e7837c0d480dd8d6de","value":" 440M/440M [00:02&lt;00:00, 201MB/s]"}},"db400aad92ad449eb08c29ad43c38774":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc1cc80bd35b4d5dae4679b8825368f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc391f34db0e43ae96f1bc5079279edd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5eb0fe60340413fb5161245a1a5096f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6cac9b8ec2540d6a4acfead90020e91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb019431ea60438095147927a0935bbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed790f27239244649065667c37f56eb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef619ee29eca42038cd174dac32da185":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3591226420045f883cad3c57057c3ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_387cac20b6294c009cf4f1f1d9440597","IPY_MODEL_8f4e34afb9cf4030977b9940bfa279e0","IPY_MODEL_d7be6f8f41ca4f36a0e5beb3e49a1a1e"],"layout":"IPY_MODEL_a4c828db3926417fa793da999dd17166"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}
