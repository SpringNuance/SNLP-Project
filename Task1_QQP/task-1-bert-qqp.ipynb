{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013721,"end_time":"2024-04-15T18:36:27.638861","exception":false,"start_time":"2024-04-15T18:36:27.625140","status":"completed"},"tags":[]},"source":["# Fine-Tuning BERT on Quora Question pairs\n","\n","# Introduction\n","\n","In this project, we would use a variety of BERT models (BERT, RoBERTa, ALBERT, DistilBERT, DeBERTa) with the HuggingFace PyTorch library to fine-tune a model to fit the QQP dataset. \n","\n","### BERT (Bidirectional Encoder Representations from Transformers) \n","\n","Original model code [here](https://github.com/google-research/bert) for NLP tasks.\n","\n","BERT consists of 12 Transformer Encoding layers (or 24 for large BERT)\n","\n","\n","# Quora Question Pairs Dataset\n","[Quora](https://www.quora.com/) is a question-and-answer website where questions are asked, answered, followed, and edited by Internet users, either factually or in the form of opinions. Quora was co-founded by former Facebook employees Adam D'Angelo and Charlie Cheever in June 2009. website was made available to the public for the first time on June 21, 2010. Today the website is available in many languages.\n","\n","Over 100 million people visit Quora every month, so it's no surprise that many people ask similarly worded questions. Multiple questions with the same intent can cause seekers to spend more time finding the best answer to their question, and make writers feel they need to answer multiple versions of the same question.\n","\n","The goal is to predict which of the provided pairs of questions contain two questions with the same meaning. The ground truth is the set of labels that have been supplied by human experts. The dataset itself can be downloaded from kaggle: [here](https://www.kaggle.com/c/quora-question-pairs/).\n","\n","## Data fields\n","* id - the id of a training set question pair\n","* qid1, qid2 - unique ids of each question (only available in train.csv)\n","* question1, question2 - the full text of each question\n","* is_duplicate - the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise."]},{"cell_type":"markdown","metadata":{},"source":["To make use of GPU, this notebook should be run on Google Colab or Kaggle. It is highly inadvisable to run this notebook on a local machine as it would take a very long time to train the model. However you can run on local for testing purposes."]},{"cell_type":"code","execution_count":26,"id":"950698a9","metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:00.255357Z","iopub.status.busy":"2024-04-16T17:49:00.254983Z","iopub.status.idle":"2024-04-16T17:49:00.268066Z","shell.execute_reply":"2024-04-16T17:49:00.267127Z","shell.execute_reply.started":"2024-04-16T17:49:00.255328Z"},"papermill":{"duration":0.034812,"end_time":"2024-04-15T18:36:27.686693","exception":false,"start_time":"2024-04-15T18:36:27.651881","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":27,"id":"6ae6a604","metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:00.269857Z","iopub.status.busy":"2024-04-16T17:49:00.269521Z","iopub.status.idle":"2024-04-16T17:49:10.524211Z","shell.execute_reply":"2024-04-16T17:49:10.523356Z","shell.execute_reply.started":"2024-04-16T17:49:00.269832Z"},"papermill":{"duration":1.594531,"end_time":"2024-04-15T18:36:29.294223","exception":false,"start_time":"2024-04-15T18:36:27.699692","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["### Importing all necessary libraries\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from tqdm import tqdm\n","from torch.utils.data import TensorDataset"]},{"cell_type":"markdown","id":"a1ef49fd","metadata":{},"source":["#### Due to memory and time limit issues, we cannot really use the whole dataset for fine tuning. As a result, we would use a subset of the dataset for training and validation."]},{"cell_type":"code","execution_count":28,"id":"d61872a8","metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:10.525798Z","iopub.status.busy":"2024-04-16T17:49:10.525368Z","iopub.status.idle":"2024-04-16T17:49:10.530027Z","shell.execute_reply":"2024-04-16T17:49:10.529153Z","shell.execute_reply.started":"2024-04-16T17:49:10.525771Z"},"trusted":true},"outputs":[],"source":["num_train_plus_test = 20 # Later, train and test data ratio is 80:20\n","num_val = 10 \n","num_unknown_labels_test = 10\n","# If you want to use all data, set values to None"]},{"cell_type":"code","execution_count":29,"id":"e2b6ea81","metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:10.532473Z","iopub.status.busy":"2024-04-16T17:49:10.532211Z","iopub.status.idle":"2024-04-16T17:49:10.655144Z","shell.execute_reply":"2024-04-16T17:49:10.654153Z","shell.execute_reply.started":"2024-04-16T17:49:10.532451Z"},"papermill":{"duration":1.979732,"end_time":"2024-04-15T18:36:31.288278","exception":false,"start_time":"2024-04-15T18:36:29.308546","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["10\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>133273</td>\n","      <td>213221</td>\n","      <td>213222</td>\n","      <td>How is the life of a math student? Could you d...</td>\n","      <td>Which level of prepration is enough for the ex...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>402555</td>\n","      <td>536040</td>\n","      <td>536041</td>\n","      <td>How do I control my horny emotions?</td>\n","      <td>How do you control your horniness?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>360472</td>\n","      <td>364011</td>\n","      <td>490273</td>\n","      <td>What causes stool color to change to yellow?</td>\n","      <td>What can cause stool to come out as little balls?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>150662</td>\n","      <td>155721</td>\n","      <td>7256</td>\n","      <td>What can one do after MBBS?</td>\n","      <td>What do i do after my MBBS ?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>183004</td>\n","      <td>279958</td>\n","      <td>279959</td>\n","      <td>Where can I find a power outlet for my laptop ...</td>\n","      <td>Would a second airport in Sydney, Australia be...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id    qid1    qid2                                          question1  \\\n","0  133273  213221  213222  How is the life of a math student? Could you d...   \n","1  402555  536040  536041                How do I control my horny emotions?   \n","2  360472  364011  490273       What causes stool color to change to yellow?   \n","3  150662  155721    7256                        What can one do after MBBS?   \n","4  183004  279958  279959  Where can I find a power outlet for my laptop ...   \n","\n","                                           question2  is_duplicate  \n","0  Which level of prepration is enough for the ex...             0  \n","1                 How do you control your horniness?             1  \n","2  What can cause stool to come out as little balls?             0  \n","3                       What do i do after my MBBS ?             1  \n","4  Would a second airport in Sydney, Australia be...             0  "]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# train_qqp = pd.read_csv(\"/kaggle/input/snlp-project-qqp/train.tsv\", sep=\"\\t\")\n","# dev_qqp = pd.read_csv(\"/kaggle/input/snlp-project-qqp/dev.tsv\", sep=\"\\t\")\n","\n","train_qqp = pd.read_csv(\"kaggle/input/snlp-project-qqp/train.tsv\", sep=\"\\t\", nrows=num_train_plus_test)\n","dev_qqp = pd.read_csv(\"kaggle/input/snlp-project-qqp/dev.tsv\", sep=\"\\t\", nrows=num_val)\n","\n","test_unknown_label_qqp = pd.read_csv(\"kaggle/input/snlp-project-qqp/test.tsv\", sep=\"\\t\", nrows=num_unknown_labels_test)\n","print(len(test_unknown_label_qqp))\n","train_qqp.head()"]},{"cell_type":"markdown","id":"1caa5460","metadata":{},"source":["## BertForSequenceClassification\n","\n","For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task.\n","\n","We’ll be using [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task."]},{"cell_type":"markdown","id":"b4f9a958","metadata":{},"source":["### Choosing the BERT variant and the Tokenizer\n","\n","To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary. The tokenization must be performed by the tokenizer included with BERT. This Tokenizer is build upon the WordPiece tokenizer. "]},{"cell_type":"code","execution_count":30,"id":"58d6b12b","metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:49:10.656899Z","iopub.status.busy":"2024-04-16T17:49:10.656509Z","iopub.status.idle":"2024-04-16T17:49:10.718193Z","shell.execute_reply":"2024-04-16T17:49:10.717142Z","shell.execute_reply.started":"2024-04-16T17:49:10.656862Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The current device is cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"The current device is\", device)"]},{"cell_type":"code","execution_count":31,"id":"8897ca7c","metadata":{"execution":{"iopub.execute_input":"2024-04-16T17:50:39.883785Z","iopub.status.busy":"2024-04-16T17:50:39.883324Z","iopub.status.idle":"2024-04-16T17:50:46.725206Z","shell.execute_reply":"2024-04-16T17:50:46.723799Z","shell.execute_reply.started":"2024-04-16T17:50:39.883748Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# PLEASE CHOOSE THE BERT VARIANT MODEL\n","\n","# bert_model_name = \"bert-base-uncased\"\n","# bert_model_name = \"roberta-base\"\n","# bert_model_name = \"distilbert-base-uncased\"\n","# bert_model_name = \"albert-base-v2\"\n","bert_model_name = \"deberta-base\"\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","bert_temp_name = \"microsoft/deberta-base\" if bert_model_name == \"deberta-base\" else bert_model_name\n","\n","tokenizer = AutoTokenizer.from_pretrained(bert_temp_name)\n","bert_classification_model = AutoModelForSequenceClassification.from_pretrained(\n","    pretrained_model_name_or_path=bert_temp_name,\n","    num_labels=2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions=False, # Whether the model returns attentions weights.\n","    output_hidden_states=False, # Whether the model returns all hidden-states.\n",")\n","\n","bert_classification_model = bert_classification_model.to(device)"]},{"cell_type":"markdown","id":"4f3c9da6","metadata":{"papermill":{"duration":0.013,"end_time":"2024-04-15T18:36:31.395538","exception":false,"start_time":"2024-04-15T18:36:31.382538","status":"completed"},"tags":[]},"source":["# Tokenizing\n","To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary. "]},{"cell_type":"code","execution_count":32,"id":"2087363b","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.065233Z","iopub.status.idle":"2024-04-16T17:49:15.065615Z","shell.execute_reply":"2024-04-16T17:49:15.065445Z","shell.execute_reply.started":"2024-04-16T17:49:15.065430Z"},"papermill":{"duration":0.02437,"end_time":"2024-04-15T18:36:37.527952","exception":false,"start_time":"2024-04-15T18:36:37.503582","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Original sentence:\n"," How is the life of a math student? Could you describe your own experiences?\n","\n","Tokenized by deberta-base:\n"," ['How', 'Ġis', 'Ġthe', 'Ġlife', 'Ġof', 'Ġa', 'Ġmath', 'Ġstudent', '?', 'ĠCould', 'Ġyou', 'Ġdescribe', 'Ġyour', 'Ġown', 'Ġexperiences', '?']\n","\n","Token IDs by deberta-base:\n"," [6179, 16, 5, 301, 9, 10, 10638, 1294, 116, 9918, 47, 6190, 110, 308, 3734, 116]\n"]}],"source":["example_question = train_qqp['question1'][0]\n","\n","print(f\"Original sentence:\\n {example_question}\")\n","\n","example_tokens = tokenizer.tokenize(example_question)\n","\n","print(f\"\\nTokenized by {bert_model_name}:\\n {example_tokens}\")\n","\n","example_tokens_ID = tokenizer.convert_tokens_to_ids(example_tokens)\n","print(f\"\\nToken IDs by {bert_model_name}:\\n {example_tokens_ID}\")"]},{"cell_type":"markdown","id":"1c610c71","metadata":{"papermill":{"duration":0.014173,"end_time":"2024-04-15T18:36:37.556061","exception":false,"start_time":"2024-04-15T18:36:37.541888","status":"completed"},"tags":[]},"source":["We can combine ``tokenize`` and ``convert_tokens_to_ids`` with the method ``encode``:"]},{"cell_type":"code","execution_count":33,"id":"fd21d5ef","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.066838Z","iopub.status.idle":"2024-04-16T17:49:15.067224Z","shell.execute_reply":"2024-04-16T17:49:15.067038Z","shell.execute_reply.started":"2024-04-16T17:49:15.067024Z"},"papermill":{"duration":0.023133,"end_time":"2024-04-15T18:36:37.595157","exception":false,"start_time":"2024-04-15T18:36:37.572024","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Original sentence:\n"," How is the life of a math student? Could you describe your own experiences?\n","\n","Token IDs by deberta-base:\n"," [1, 6179, 16, 5, 301, 9, 10, 10638, 1294, 116, 9918, 47, 6190, 110, 308, 3734, 116, 2]\n"]}],"source":["example_question = train_qqp['question1'][0]\n","\n","print(f\"Original sentence:\\n {example_question}\")\n","\n","example_tokens_ID = tokenizer.encode(example_question)\n","\n","print(f\"\\nToken IDs by {bert_model_name}:\\n {example_tokens_ID}\")"]},{"cell_type":"markdown","id":"6c454405","metadata":{"papermill":{"duration":0.014143,"end_time":"2024-04-15T18:36:37.623786","exception":false,"start_time":"2024-04-15T18:36:37.609643","status":"completed"},"tags":[]},"source":["We can see we got two extra tokens at the start and at the end compared to previous versions. Let's see what they are:"]},{"cell_type":"code","execution_count":34,"id":"6ab18a08","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.068323Z","iopub.status.idle":"2024-04-16T17:49:15.068649Z","shell.execute_reply":"2024-04-16T17:49:15.068493Z","shell.execute_reply.started":"2024-04-16T17:49:15.068480Z"},"papermill":{"duration":9.724492,"end_time":"2024-04-15T18:36:47.362514","exception":false,"start_time":"2024-04-15T18:36:37.638022","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'[CLS]How is the life of a math student? Could you describe your own experiences?[SEP]'"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(example_tokens_ID)"]},{"cell_type":"markdown","id":"8a57b92a","metadata":{"papermill":{"duration":0.022156,"end_time":"2024-04-15T18:36:47.406755","exception":false,"start_time":"2024-04-15T18:36:47.384599","status":"completed"},"tags":[]},"source":["## Special Tokens\n","``[SEP]`` - At the end of every sentence, we need to append the special ``[SEP]`` token.\n","\n","This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (remeber BERT was trained intially to perdict question-answering task).\n","\n","``[CLS]`` - For classification tasks, we must prepend the special ``[CLS]`` token to the beginning of every sentence.\n","\n","This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output.\n","\n","So now let's see how to encode the two questions together:"]},{"cell_type":"code","execution_count":35,"id":"8cb20c3c","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.070182Z","iopub.status.idle":"2024-04-16T17:49:15.070482Z","shell.execute_reply":"2024-04-16T17:49:15.070347Z","shell.execute_reply.started":"2024-04-16T17:49:15.070335Z"},"papermill":{"duration":0.028661,"end_time":"2024-04-15T18:36:47.458928","exception":false,"start_time":"2024-04-15T18:36:47.430267","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'[CLS]How is the life of a math student? Could you describe your own experiences?[SEP]Which level of prepration is enough for the exam jlpt5?[SEP]'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["example_question_1 = train_qqp['question1'][0]\n","example_question_2 = train_qqp['question2'][0]\n","\n","encoded_pair = tokenizer.encode(example_question_1, example_question_2)\n","tokenizer.decode(encoded_pair)"]},{"cell_type":"markdown","id":"1f387605","metadata":{"papermill":{"duration":0.014418,"end_time":"2024-04-15T18:36:47.488328","exception":false,"start_time":"2024-04-15T18:36:47.473910","status":"completed"},"tags":[]},"source":["## Sentence Length\n","\n","The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n","\n","BERT has two constraints:\n","\n","1. All sentences must be padded or truncated to a single, fixed length.\n","2. The maximum sentence length is 512 tokens.\n","Padding is done with a special ``[PAD]`` token, which is at index 0 in the BERT vocabulary.\n","\n","The maximum length does impact training and evaluation speed.\n","\n","Before we are ready to encode our text, though, we need to decide on a maximum sentence length for padding / truncating to.\n","\n","Let's find the maximum length:"]},{"cell_type":"code","execution_count":36,"id":"4213e515","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.071460Z","iopub.status.idle":"2024-04-16T17:49:15.071769Z","shell.execute_reply":"2024-04-16T17:49:15.071627Z","shell.execute_reply.started":"2024-04-16T17:49:15.071614Z"},"papermill":{"duration":2.103722,"end_time":"2024-04-15T18:36:49.606625","exception":false,"start_time":"2024-04-15T18:36:47.502903","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:00<00:00, 2812.80it/s]\n","100%|██████████| 20/20 [00:00<00:00, 4998.87it/s]"]},{"name":"stdout","output_type":"stream","text":["The maximum sentence length is  61\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["tqdm.pandas()\n","train_qqp[\"question1_length\"] = train_qqp[\"question1\"].progress_apply(lambda question: \n","                                                        len(tokenizer.tokenize(question)))\n","train_qqp[\"question2_length\"] = train_qqp[\"question2\"].progress_apply(lambda question: \n","                                                        len(tokenizer.tokenize(question)))\n","train_qqp[\"joint_length\"] = train_qqp[\"question1_length\"] + train_qqp[\"question2_length\"]\n","\n","MAX_LENGTH = train_qqp[\"joint_length\"].max()\n","\n","print(\"The maximum sentence length is \", MAX_LENGTH)"]},{"cell_type":"markdown","id":"8f42d7e1","metadata":{"papermill":{"duration":0.016526,"end_time":"2024-04-15T18:36:49.639951","exception":false,"start_time":"2024-04-15T18:36:49.623425","status":"completed"},"tags":[]},"source":["### Now we construct the training, validation, testing dataset with known labels and testing dataset with unknown labels"]},{"cell_type":"code","execution_count":37,"id":"8cc6f423","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.073935Z","iopub.status.idle":"2024-04-16T17:49:15.074294Z","shell.execute_reply":"2024-04-16T17:49:15.074147Z","shell.execute_reply.started":"2024-04-16T17:49:15.074128Z"},"papermill":{"duration":0.032564,"end_time":"2024-04-15T18:36:49.689023","exception":false,"start_time":"2024-04-15T18:36:49.656459","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["X_train, X_test_known_labels, y_train, y_test_known_labels = train_test_split(train_qqp[[\"question1\", \"question2\"]], \n","                                                    train_qqp[\"is_duplicate\"], test_size=0.2, random_state=42)\n","X_val = dev_qqp[[\"question1\", \"question2\"]]\n","y_val = dev_qqp[\"is_duplicate\"]\n","\n","X_test_unknown_labels = test_unknown_label_qqp[[\"question1\", \"question2\"]]"]},{"cell_type":"markdown","id":"e9a674c1","metadata":{"papermill":{"duration":0.016289,"end_time":"2024-04-15T18:36:49.721709","exception":false,"start_time":"2024-04-15T18:36:49.705420","status":"completed"},"tags":[]},"source":["# Tokenize dataset and create Dataloader\n","\n","Now we’re ready to perform the real tokenization.\n","\n","The tokenizer.encode_plus function combines multiple steps for us:\n","\n","1. Split the sentence into tokens.\n","2. Add the special ``[CLS]`` and ``[SEP]`` tokens.\n","3. Map the tokens to their IDs.\n","4. Pad or truncate all sentences to the same length.\n","5. Create the attention masks which explicitly differentiate real tokens from ``[PAD]`` tokens.\n","\n","Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus)."]},{"cell_type":"code","execution_count":38,"id":"b330ed62","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.075563Z","iopub.status.idle":"2024-04-16T17:49:15.075901Z","shell.execute_reply":"2024-04-16T17:49:15.075752Z","shell.execute_reply.started":"2024-04-16T17:49:15.075738Z"},"papermill":{"duration":0.101843,"end_time":"2024-04-15T18:36:49.840093","exception":false,"start_time":"2024-04-15T18:36:49.738250","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[    1, 10836,    38,  2914,   589,     9,  5703,   114,    38,  1705,\n","            75,  3042,     5,  8045,  4863,    11, 13544,  1821,  2475,   116,\n","             2, 29972,     9,     5,  5639,    35,   318,    38,   185,    10,\n","           200,   163,  5944,    11,     5,  5570,  1821,     9, 14321,  4455,\n","             6,    64,    38,    28, 31882,    31, 12358,     4,  4803,     4,\n","            50,  2731,  9352,   116,     2,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["MAX_LENGTH = 327\n","\n","tokenizer.encode_plus(X_train.iloc[0][\"question1\"], \n","                      X_train.iloc[0][\"question2\"], \n","                      max_length=MAX_LENGTH, \n","                      padding='max_length', \n","                      return_attention_mask=True, \n","                      return_tensors='pt', \n","                      truncation=True)"]},{"cell_type":"markdown","id":"eebbc193","metadata":{"papermill":{"duration":0.016895,"end_time":"2024-04-15T18:36:49.873851","exception":false,"start_time":"2024-04-15T18:36:49.856956","status":"completed"},"tags":[]},"source":["So what we got:\n","\n","1. input_ids - Token ids padded with 0 at the end.\n","2. token_type_ids - This array indicates bert what is the first sentence and what is the seconds. In case of classification of only one sentance this array is redundant.\n","3. attention_mask - The “Attention Mask” is simply an array of 1s and 0s indicating which tokens are padding and which aren’t. This mask tells the “Self-Attention” mechanism in BERT not to incorporate these ``[PAD]`` tokens into its interpretation of the sentence.\n","\n","All the array are in the size of ``max_length``."]},{"cell_type":"code","execution_count":39,"id":"4b6e8051","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.077271Z","iopub.status.idle":"2024-04-16T17:49:15.077758Z","shell.execute_reply":"2024-04-16T17:49:15.077568Z","shell.execute_reply.started":"2024-04-16T17:49:15.077544Z"},"papermill":{"duration":0.028634,"end_time":"2024-04-15T18:36:49.919151","exception":false,"start_time":"2024-04-15T18:36:49.890517","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def convert_to_dataset_torch(features, labels):\n","    input_ids = []\n","    attention_masks = []\n","    token_type_ids = []\n","    for _, row in tqdm(features.iterrows(), total=features.shape[0]):\n","        encoded_dict = tokenizer.encode_plus(row[\"question1\"], \n","                                             row[\"question2\"], \n","                                             padding='max_length', \n","                                             return_attention_mask=True, \n","                                             return_tensors='pt', \n","                                             truncation=True)\n","        # print(encoded_dict.keys())\n","        \n","        # Add the encoded sentences to the list.\n","        input_ids.append(encoded_dict['input_ids'])\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks.append(encoded_dict['attention_mask'])\n","        \n","        if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","            token_type_ids.append(encoded_dict[\"token_type_ids\"])\n","        \n","    # Convert the lists into tensors.\n","    if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","\n","        input_ids = torch.cat(input_ids, dim=0)\n","        token_type_ids = torch.cat(token_type_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","        labels = torch.tensor(labels.values)\n","        \n","        print(\"Shape of input_ids is\", input_ids.shape)\n","        print(\"Shape of token_type_ids is\", token_type_ids.shape)\n","        print(\"Shape of attention_masks is\", attention_masks.shape)\n","        print(\"Shape of labels is\", labels.shape)\n","        \n","        return TensorDataset(input_ids, attention_masks, token_type_ids, labels)\n","    \n","    elif bert_model_name in [\"roberta-base\", \"distilbert-base-uncased\"]:\n","        # roberta does not have token_type_ids\n","        input_ids = torch.cat(input_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","        labels = torch.tensor(labels.values)\n","        \n","        print(\"Shape of input_ids is\", input_ids.shape)\n","        print(\"Shape of attention_masks is\", attention_masks.shape)\n","        print(\"Shape of labels is\", labels.shape)\n","        \n","        return TensorDataset(input_ids, attention_masks, labels)\n","    "]},{"cell_type":"markdown","id":"5011868a","metadata":{"papermill":{"duration":0.016871,"end_time":"2024-04-15T18:36:49.953559","exception":false,"start_time":"2024-04-15T18:36:49.936688","status":"completed"},"tags":[]},"source":["We’ll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory:"]},{"cell_type":"code","execution_count":40,"id":"33410a9f","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.078914Z","iopub.status.idle":"2024-04-16T17:49:15.079298Z","shell.execute_reply":"2024-04-16T17:49:15.079127Z","shell.execute_reply.started":"2024-04-16T17:49:15.079091Z"},"papermill":{"duration":8.287055,"end_time":"2024-04-15T18:36:58.257606","exception":false,"start_time":"2024-04-15T18:36:49.970551","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 16/16 [00:00<00:00, 841.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Shape of input_ids is torch.Size([16, 512])\n","Shape of token_type_ids is torch.Size([16, 512])\n","Shape of attention_masks is torch.Size([16, 512])\n","Shape of labels is torch.Size([16])\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["train_tensor = convert_to_dataset_torch(X_train, y_train)"]},{"cell_type":"code","execution_count":41,"id":"bef6d73a","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.081080Z","iopub.status.idle":"2024-04-16T17:49:15.081450Z","shell.execute_reply":"2024-04-16T17:49:15.081292Z","shell.execute_reply.started":"2024-04-16T17:49:15.081279Z"},"papermill":{"duration":2.021747,"end_time":"2024-04-15T18:37:00.303924","exception":false,"start_time":"2024-04-15T18:36:58.282177","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:00<00:00, 769.34it/s]"]},{"name":"stdout","output_type":"stream","text":["Shape of input_ids is torch.Size([10, 512])\n","Shape of token_type_ids is torch.Size([10, 512])\n","Shape of attention_masks is torch.Size([10, 512])\n","Shape of labels is torch.Size([10])\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["val_tensor = convert_to_dataset_torch(X_val, y_val)"]},{"cell_type":"code","execution_count":42,"id":"34b0531e","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.082864Z","iopub.status.idle":"2024-04-16T17:49:15.083266Z","shell.execute_reply":"2024-04-16T17:49:15.083074Z","shell.execute_reply.started":"2024-04-16T17:49:15.083060Z"},"papermill":{"duration":0.035939,"end_time":"2024-04-15T18:37:00.365433","exception":false,"start_time":"2024-04-15T18:37:00.329494","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import multiprocessing\n","\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it here.\n","\n","batch_size = 5\n","\n","core_number = multiprocessing.cpu_count()\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_tensor,  # The training samples.\n","            sampler = RandomSampler(train_tensor), # Select batches randomly\n","            batch_size = batch_size, # Trains with this batch size.\n","            num_workers = core_number\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","val_dataloader = DataLoader(\n","            val_tensor, # The validation samples.\n","            sampler = SequentialSampler(val_tensor), # Pull out batches sequentially.\n","            batch_size = batch_size, # Evaluate with this batch size.\n","            num_workers = core_number\n","        )"]},{"cell_type":"markdown","id":"2d5fae86","metadata":{"papermill":{"duration":0.025836,"end_time":"2024-04-15T18:37:05.155030","exception":false,"start_time":"2024-04-15T18:37:05.129194","status":"completed"},"tags":[]},"source":["# Training Loop\n","Helper function for formatting elapsed times as ``hh:mm:ss``:"]},{"cell_type":"code","execution_count":43,"id":"8da55dba","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.086449Z","iopub.status.idle":"2024-04-16T17:49:15.086813Z","shell.execute_reply":"2024-04-16T17:49:15.086643Z","shell.execute_reply.started":"2024-04-16T17:49:15.086629Z"},"papermill":{"duration":0.033386,"end_time":"2024-04-15T18:37:05.215284","exception":false,"start_time":"2024-04-15T18:37:05.181898","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"markdown","id":"5c1858a6","metadata":{"papermill":{"duration":0.025281,"end_time":"2024-04-15T18:37:05.266175","exception":false,"start_time":"2024-04-15T18:37:05.240894","status":"completed"},"tags":[]},"source":["### This function trains the batches from the train_dataloader"]},{"cell_type":"code","execution_count":44,"id":"b652071c","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.088478Z","iopub.status.idle":"2024-04-16T17:49:15.088846Z","shell.execute_reply":"2024-04-16T17:49:15.088671Z","shell.execute_reply.started":"2024-04-16T17:49:15.088657Z"},"papermill":{"duration":0.036185,"end_time":"2024-04-15T18:37:05.328085","exception":false,"start_time":"2024-04-15T18:37:05.291900","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def train_batch(epoch, bert_classification_model, train_dataloader, optimizer, scheduler, metric):\n","    \n","    total_train_loss = 0\n","    total_train_accuracy = 0\n","    \n","    for batch in tqdm(train_dataloader, desc=f\"Training epoch: {epoch}\", unit=\"batch\"):\n","        \n","        if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","\n","            # Unpack batch from dataloader.\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            token_type_ids = batch[2].to(device)\n","            labels = batch[3].to(device)\n","            \n","            bert_classification_model.zero_grad()\n","            \n","            # Forward pass\n","            outputs = bert_classification_model(input_ids, \n","                                token_type_ids=token_type_ids, \n","                                attention_mask=attention_masks, \n","                                labels=labels)\n","            \n","        elif bert_model_name in [\"roberta-base\", \"distilbert-base-uncased\"]:\n","            # Unpack batch from dataloader.\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            labels = batch[2].to(device)\n","            \n","            bert_classification_model.zero_grad()\n","            \n","            # Forward pass\n","            outputs = bert_classification_model(input_ids, \n","                                attention_mask=attention_masks, \n","                                labels=labels)\n","            \n","        loss = outputs.loss\n","        logits = outputs.logits\n","\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(bert_classification_model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        y_pred = np.argmax(logits.cpu().detach().numpy(), axis=1).flatten()\n","        \n","        total_train_accuracy += metric(labels.cpu(), y_pred)\n","\n","    return total_train_loss, total_train_accuracy"]},{"cell_type":"markdown","id":"9aeafe8a","metadata":{"papermill":{"duration":0.024768,"end_time":"2024-04-15T18:37:05.379318","exception":false,"start_time":"2024-04-15T18:37:05.354550","status":"completed"},"tags":[]},"source":["### This function validates the batches from the val_dataloader"]},{"cell_type":"code","execution_count":45,"id":"cd74d073","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.089914Z","iopub.status.idle":"2024-04-16T17:49:15.090265Z","shell.execute_reply":"2024-04-16T17:49:15.090090Z","shell.execute_reply.started":"2024-04-16T17:49:15.090078Z"},"papermill":{"duration":0.039203,"end_time":"2024-04-15T18:37:05.445136","exception":false,"start_time":"2024-04-15T18:37:05.405933","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def val_batch(epoch, bert_classification_model, val_dataloader, metric):\n","    total_val_loss = 0\n","    total_val_accuracy = 0\n","    predicted_logits , predicted_labels = [], []\n","    \n","    for batch in tqdm(val_dataloader, desc=f\"Validating epoch: {epoch}\", unit=\"batch\"):\n","        # Unpack batch from dataloader.\n","        \n","        if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            token_type_ids = batch[2].to(device)\n","            labels = batch[3].to(device)\n","\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions.\n","                outputs = bert_classification_model(input_ids, \n","                                    token_type_ids=token_type_ids, \n","                                    attention_mask=attention_masks,\n","                                    labels=labels)\n","                loss = outputs.loss\n","                logits = outputs.logits\n","                \n","        elif bert_model_name in [\"roberta-base\", \"distilbert-base-uncased\"]:\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            labels = batch[2].to(device)\n","\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions.\n","                outputs = bert_classification_model(input_ids, \n","                                    attention_mask=attention_masks,\n","                                    labels=labels)\n","                loss = outputs.loss\n","                logits = outputs.logits\n","            \n","        total_val_loss += loss.item()\n","        \n","        y_pred = np.argmax(logits.cpu().detach().numpy(), axis=1).flatten()\n","        \n","        total_val_accuracy += metric(labels.cpu(), y_pred)\n","        \n","        predicted_logits.extend(logits.cpu().detach().numpy().tolist())\n","        predicted_labels.extend(y_pred.tolist())\n","    \n","    return total_val_loss, total_val_accuracy, predicted_logits, predicted_labels"]},{"cell_type":"markdown","id":"af899e79","metadata":{},"source":["### This function predicts the classes of the batches from the test_dataloader. Now the test_dataloader only contains X_test without y_test (which is None)"]},{"cell_type":"code","execution_count":46,"id":"d4e26545","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.091442Z","iopub.status.idle":"2024-04-16T17:49:15.091765Z","shell.execute_reply":"2024-04-16T17:49:15.091607Z","shell.execute_reply.started":"2024-04-16T17:49:15.091594Z"},"trusted":true},"outputs":[],"source":["def predict_batch(bert_classification_model, test_dataloader):\n","    \n","    predicted_logits , predicted_labels = [], []\n","    \n","    for batch in tqdm(val_dataloader, desc=f\"Predicting\", unit=\"batch\"):\n","        # Unpack batch from dataloader.\n","        \n","        if bert_model_name in [\"bert-base-uncased\", \"albert-base-v2\", \"deberta-base\"]:\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","            token_type_ids = batch[2].to(device)\n","\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions.\n","                outputs = bert_classification_model(input_ids, \n","                                    token_type_ids=token_type_ids, \n","                                    attention_mask=attention_masks)\n","                logits = outputs.logits\n","                \n","        elif bert_model_name in [\"roberta-base\", \"distilbert-base-uncased\"]:\n","            input_ids = batch[0].to(device)\n","            attention_masks = batch[1].to(device)\n","\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions.\n","                outputs = bert_classification_model(input_ids, \n","                                    attention_mask=attention_masks)\n","                logits = outputs.logits\n","            \n","        y_pred = np.argmax(logits.cpu().detach().numpy(), axis=1).flatten()\n","                \n","        predicted_logits.extend(logits.cpu().detach().numpy().tolist())\n","        predicted_labels.extend(y_pred.tolist())\n","    \n","    return predicted_logits, predicted_labels"]},{"cell_type":"code","execution_count":47,"id":"4e69a2d3","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.093424Z","iopub.status.idle":"2024-04-16T17:49:15.093733Z","shell.execute_reply":"2024-04-16T17:49:15.093595Z","shell.execute_reply.started":"2024-04-16T17:49:15.093583Z"},"papermill":{"duration":0.040053,"end_time":"2024-04-15T18:37:05.566326","exception":false,"start_time":"2024-04-15T18:37:05.526273","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import random\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","\n","def fine_tuning_pretrained_model(epochs, bert_classification_model, \n","                                 train_dataloader, \n","                                 val_dataloader, \n","                                 optimizer, \n","                                 scheduler,\n","                                 metric\n","                                 ):\n","    \n","    fine_tuning_statistics = []\n","    \n","    for epoch in range(1, epochs + 1):\n","\n","        #################\n","        # TRAINING PART #\n","        #################\n","\n","        t_begin_train = time.time()\n","        \n","        bert_classification_model.train()\n","        \n","        total_train_loss, total_train_accuracy = train_batch(epoch,\n","                                       bert_classification_model,\n","                                       train_dataloader,\n","                                       optimizer,\n","                                       scheduler,\n","                                       metric\n","                                       )\n","        \n","        # Calculate the average training loss for all batches.\n","        average_train_loss = total_train_loss / len(train_dataloader)\n","        print(f\"  Average training loss: {average_train_loss}\")\n","\n","        # Calculate the average training accuracy for all batches.\n","        average_train_accuracy = total_train_accuracy / len(train_dataloader)\n","        print(f\"  Average training accuracy: {average_train_accuracy}\")\n","        \n","        t_end_train = time.time()\n","\n","        training_time = format_time(t_end_train - t_begin_train)\n","        print(f\"  Training time took: {training_time}\")\n","        \n","        ###################\n","        # VALIDATING PART #\n","        ###################\n","\n","        t_begin_val = time.time()\n","        \n","        bert_classification_model.eval()\n","        \n","        total_val_loss, total_val_accuracy,\\\n","        predicted_logits, predicted_labels = val_batch(epoch, \n","                                                        bert_classification_model,\n","                                                        val_dataloader,\n","                                                        metric)\n","        \n","        # Calculate the average validation loss for all batches.\n","        average_val_loss = total_val_loss / len(val_dataloader)\n","        print(f\"  Average validation loss: {average_val_loss}\")\n","\n","        # Calculate the average validation accuracy for all batches.\n","        average_val_accuracy = total_val_accuracy / len(val_dataloader)\n","        print(f\"  Average validation accuracy: {average_val_accuracy}\")\n","    \n","        t_end_val = time.time()\n","\n","        validation_time = format_time(t_end_val - t_begin_val)\n","        print(f\"  Validation time took: {validation_time}\")\n","    \n","        # Record all statistics from this epoch.\n","        fine_tuning_statistics.append(\n","            {\n","                'epoch': epoch,\n","                'train_loss': average_train_loss,\n","                'train_accuracy': average_train_accuracy,\n","                'train_time': training_time,\n","                'val_loss': average_val_loss,\n","                'val_accuracy': average_val_accuracy,\n","                'val_time': validation_time\n","            }\n","        )\n","        \n","\n","    print(\"\")\n","    print(\"Training complete!\")\n","\n","    return fine_tuning_statistics"]},{"cell_type":"markdown","id":"71bcceab","metadata":{"papermill":{"duration":0.027716,"end_time":"2024-04-15T18:37:05.620847","exception":false,"start_time":"2024-04-15T18:37:05.593131","status":"completed"},"tags":[]},"source":["# Optimizer & Learning Rate Scheduler\n","Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n","\n","For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n","\n","* Batch size: 16, 32\n","* Learning rate (Adam): 5e-5, 3e-5, 2e-5\n","* Number of epochs: 2, 3, 4\n","\n","I chose:\n","* Batch size: 10 (due to memory limit of Kaggle)\n","* Learning rate: 2e-5\n","* Number of epochs: 4\n","\n","We’re ready to kick off the training:"]},{"cell_type":"code","execution_count":48,"id":"70e75719","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.095227Z","iopub.status.idle":"2024-04-16T17:49:15.095558Z","shell.execute_reply":"2024-04-16T17:49:15.095412Z","shell.execute_reply.started":"2024-04-16T17:49:15.095399Z"},"papermill":{"duration":2970.860026,"end_time":"2024-04-15T19:26:36.507068","exception":false,"start_time":"2024-04-15T18:37:05.647042","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training epoch: 1: 100%|██████████| 4/4 [02:05<00:00, 31.27s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["  Average training loss: 0.6935897171497345\n","  Average training accuracy: 0.6\n","  Training time took: 0:02:05\n"]},{"name":"stderr","output_type":"stream","text":["Validating epoch: 1: 100%|██████████| 2/2 [00:25<00:00, 12.51s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["  Average validation loss: 0.6853211224079132\n","  Average validation accuracy: 0.6000000000000001\n","  Validation time took: 0:00:25\n"]},{"name":"stderr","output_type":"stream","text":["Training epoch: 2:   0%|          | 0/4 [00:10<?, ?batch/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[48], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(adamw_optimizer, \n\u001b[0;32m     21\u001b[0m                                             num_warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \n\u001b[0;32m     22\u001b[0m                                             num_training_steps \u001b[38;5;241m=\u001b[39m total_steps)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Finally, we start to train the model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m fine_tuning_statistics \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tuning_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbert_classification_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43madamw_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccuracy_score\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[47], line 29\u001b[0m, in \u001b[0;36mfine_tuning_pretrained_model\u001b[1;34m(epochs, bert_classification_model, train_dataloader, val_dataloader, optimizer, scheduler, metric)\u001b[0m\n\u001b[0;32m     25\u001b[0m t_begin_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     27\u001b[0m bert_classification_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 29\u001b[0m total_train_loss, total_train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mbert_classification_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                               \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmetric\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                               \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Calculate the average training loss for all batches.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m average_train_loss \u001b[38;5;241m=\u001b[39m total_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n","Cell \u001b[1;32mIn[44], line 6\u001b[0m, in \u001b[0;36mtrain_batch\u001b[1;34m(epoch, bert_classification_model, train_dataloader, optimizer, scheduler, metric)\u001b[0m\n\u001b[0;32m      3\u001b[0m total_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m total_train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining epoch: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbert_model_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malbert-base-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeberta-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Unpack batch from dataloader.\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:1084\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m   1081\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m   1082\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1084\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n","File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:1016\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m   1014\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m-> 1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from torch.optim import AdamW\n","from sklearn.metrics import accuracy_score\n","\n","adamw_optimizer = AdamW(bert_classification_model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(adamw_optimizer, \n","                                            num_warmup_steps = 0, \n","                                            num_training_steps = total_steps)\n","\n","# Finally, we start to train the model\n","fine_tuning_statistics = fine_tuning_pretrained_model(\n","    epochs,\n","    bert_classification_model,\n","    train_dataloader,\n","    val_dataloader,\n","    adamw_optimizer,\n","    scheduler,\n","    accuracy_score)"]},{"cell_type":"markdown","id":"1a8a0380","metadata":{"papermill":{"duration":0.388697,"end_time":"2024-04-15T19:26:37.242050","exception":false,"start_time":"2024-04-15T19:26:36.853353","status":"completed"},"tags":[]},"source":["### Let’s view the summary of the training process. First we create a folder to save the results for the BERT variant"]},{"cell_type":"code","execution_count":null,"id":"5db8aeab","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.096916Z","iopub.status.idle":"2024-04-16T17:49:15.097264Z","shell.execute_reply":"2024-04-16T17:49:15.097082Z","shell.execute_reply.started":"2024-04-16T17:49:15.097070Z"},"trusted":true},"outputs":[],"source":["if not os.path.exists(f\"{bert_model_name}\"):\n","    os.makedirs(f\"{bert_model_name}\")"]},{"cell_type":"code","execution_count":null,"id":"6dcc8014","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.098957Z","iopub.status.idle":"2024-04-16T17:49:15.099436Z","shell.execute_reply":"2024-04-16T17:49:15.099221Z","shell.execute_reply.started":"2024-04-16T17:49:15.099203Z"},"papermill":{"duration":0.360694,"end_time":"2024-04-15T19:26:37.941464","exception":false,"start_time":"2024-04-15T19:26:37.580770","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["df_stats = pd.DataFrame(fine_tuning_statistics).set_index('epoch')\n","# Saving the fine_tuning_statistics\n","df_stats.to_csv(f\"{bert_model_name}/fine_tuning_statistics.csv\")\n","df_stats"]},{"cell_type":"code","execution_count":null,"id":"061d88a3","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.100729Z","iopub.status.idle":"2024-04-16T17:49:15.101030Z","shell.execute_reply":"2024-04-16T17:49:15.100894Z","shell.execute_reply.started":"2024-04-16T17:49:15.100882Z"},"papermill":{"duration":0.656377,"end_time":"2024-04-15T19:26:38.936759","exception":false,"start_time":"2024-04-15T19:26:38.280382","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from matplotlib import pyplot\n","\n","%matplotlib inline\n","\n","pyplot.plot(df_stats['train_loss'], 'b-o', label=\"training\")\n","pyplot.plot(df_stats['val_loss'], 'g-o', label=\"validation\")\n","pyplot.title(f\"{bert_model_name}: training & validation loss\", fontsize=15)\n","pyplot.xlabel(\"Epoch\", fontsize=14)\n","pyplot.ylabel(\"Loss\", fontsize=14)\n","pyplot.legend(frameon=False, fontsize=14)\n","pyplot.xticks(df_stats.index.values.tolist(), fontsize=12)\n","pyplot.yticks(fontsize=12)\n","pyplot.savefig(f\"{bert_model_name}/train_val_loss_plot.png\")\n","pyplot.show()"]},{"cell_type":"code","execution_count":null,"id":"b7071f5c","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.101922Z","iopub.status.idle":"2024-04-16T17:49:15.102260Z","shell.execute_reply":"2024-04-16T17:49:15.102083Z","shell.execute_reply.started":"2024-04-16T17:49:15.102071Z"},"trusted":true},"outputs":[],"source":["from matplotlib import pyplot\n","\n","%matplotlib inline\n","\n","pyplot.plot(df_stats['train_accuracy'], 'b-o', label=\"training\")\n","pyplot.plot(df_stats['val_accuracy'], 'g-o', label=\"validation\")\n","pyplot.title(f\"{bert_model_name}: training & validation accuracy\", fontsize=15)\n","pyplot.xlabel(\"Epoch\", fontsize=14)\n","pyplot.ylabel(\"Loss\", fontsize=14)\n","pyplot.legend(frameon=False, fontsize=14)\n","pyplot.xticks(df_stats.index.values.tolist(), fontsize=12)\n","pyplot.yticks(fontsize=12)\n","pyplot.savefig(f\"{bert_model_name}/train_val_accuracy_plot.png\")\n","pyplot.show()"]},{"cell_type":"markdown","id":"db676852","metadata":{"papermill":{"duration":0.384476,"end_time":"2024-04-15T19:26:39.668675","exception":false,"start_time":"2024-04-15T19:26:39.284199","status":"completed"},"tags":[]},"source":["## Performance on test set and prediction"]},{"cell_type":"code","execution_count":null,"id":"d86a0156","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.103474Z","iopub.status.idle":"2024-04-16T17:49:15.103773Z","shell.execute_reply":"2024-04-16T17:49:15.103636Z","shell.execute_reply.started":"2024-04-16T17:49:15.103623Z"},"papermill":{"duration":2.355805,"end_time":"2024-04-15T19:26:42.364086","exception":false,"start_time":"2024-04-15T19:26:40.008281","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["print(type(y_test_known_labels))\n","test_tensor_known_labels = convert_to_dataset_torch(X_test_known_labels, y_test_known_labels)\n","test_dataloader = DataLoader(test_tensor_known_labels, \n","                             sampler=SequentialSampler(test_tensor_known_labels), \n","                             batch_size=batch_size)\n","\n","#print(len(X_test_unknown_labels))\n","#features_tensor = torch.tensor(X_test_unknown_labels.to_numpy(), dtype=torch.float32)\n","#print(features_tensor.shape)\n","\n","# Create dummy labels tensor\n","\n","dummy_labels_series = pd.Series([-1] * len(X_test_unknown_labels))\n","# print(X_test_unknown_labels.shape)\n","test_tensor_unknown_labels = convert_to_dataset_torch(X_test_unknown_labels, dummy_labels_series)\n","predict_dataloader = DataLoader(test_tensor_unknown_labels, \n","                             sampler=SequentialSampler(test_tensor_unknown_labels), \n","                             batch_size=batch_size)"]},{"cell_type":"markdown","id":"d49d5268","metadata":{"papermill":{"duration":0.362368,"end_time":"2024-04-15T19:26:43.095895","exception":false,"start_time":"2024-04-15T19:26:42.733527","status":"completed"},"tags":[]},"source":["## Evaluate on the test set with known labels\n","With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set with known labels"]},{"cell_type":"code","execution_count":null,"id":"1876a444","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.104733Z","iopub.status.idle":"2024-04-16T17:49:15.105030Z","shell.execute_reply":"2024-04-16T17:49:15.104894Z","shell.execute_reply.started":"2024-04-16T17:49:15.104883Z"},"papermill":{"duration":61.396734,"end_time":"2024-04-15T19:27:44.840416","exception":false,"start_time":"2024-04-15T19:26:43.443682","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["bert_classification_model.eval()\n","\n","total_val_loss, total_val_accuracy,\\\n","predicted_logits_val, predicted_labels_val = val_batch(None, bert_classification_model, \n","                                               test_dataloader, accuracy_score)"]},{"cell_type":"markdown","id":"95f17fb2","metadata":{},"source":["## Making prediction on the test set with unknown labels\n","\n","With the predict set prepared, we can apply our fine-tuned model to generate predictions on the test set with unknown labels"]},{"cell_type":"code","execution_count":null,"id":"724e55e5","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.106532Z","iopub.status.idle":"2024-04-16T17:49:15.106896Z","shell.execute_reply":"2024-04-16T17:49:15.106741Z","shell.execute_reply.started":"2024-04-16T17:49:15.106727Z"},"trusted":true},"outputs":[],"source":["bert_classification_model.eval()\n","\n","predicted_logits_test, predicted_labels_test = predict_batch(bert_classification_model, \n","                                                   predict_dataloader)"]},{"cell_type":"markdown","id":"d3c6a68f","metadata":{},"source":["### We construct the testing result with corresponding truth labels and predicted labels by the fine-tuned BERT model. This testing data is part of the training data (train.tsv)"]},{"cell_type":"code","execution_count":null,"id":"71c7e2b4","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.108421Z","iopub.status.idle":"2024-04-16T17:49:15.108743Z","shell.execute_reply":"2024-04-16T17:49:15.108600Z","shell.execute_reply.started":"2024-04-16T17:49:15.108586Z"},"trusted":true},"outputs":[],"source":["testing_results_known_labels = pd.DataFrame()\n","testing_results_known_labels[\"question1\"] = X_test_known_labels[\"question1\"]\n","testing_results_known_labels[\"question2\"] = X_test_known_labels[\"question2\"]\n","testing_results_known_labels[\"true_is_duplicate\"] = y_test_known_labels\n","testing_results_known_labels[\"predicted_is_duplicate\"] = predicted_labels_val\n","testing_results_known_labels.head()"]},{"cell_type":"markdown","id":"d2b1ece5","metadata":{},"source":["### We construct the testing result with no known labels (the test.tsv file) with the predicted labels by the fine-tuned BERT model"]},{"cell_type":"code","execution_count":null,"id":"1f40f022","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.112288Z","iopub.status.idle":"2024-04-16T17:49:15.112652Z","shell.execute_reply":"2024-04-16T17:49:15.112499Z","shell.execute_reply.started":"2024-04-16T17:49:15.112485Z"},"trusted":true},"outputs":[],"source":["testing_results_unknown_labels = pd.DataFrame()\n","testing_results_unknown_labels[\"question1\"] = X_test_unknown_labels[\"question1\"]\n","testing_results_unknown_labels[\"question2\"] = X_test_unknown_labels[\"question2\"]\n","testing_results_unknown_labels[\"predicted_is_duplicate\"] = predicted_labels_test\n","testing_results_unknown_labels.head()"]},{"cell_type":"markdown","id":"7414b200","metadata":{},"source":["### Saving testing results"]},{"cell_type":"code","execution_count":null,"id":"67cb02af","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.114297Z","iopub.status.idle":"2024-04-16T17:49:15.114638Z","shell.execute_reply":"2024-04-16T17:49:15.114491Z","shell.execute_reply.started":"2024-04-16T17:49:15.114477Z"},"trusted":true},"outputs":[],"source":["testing_results_known_labels.to_csv(f\"{bert_model_name}/testing_results_known_labels.csv\", index=False)\n","testing_results_unknown_labels.to_csv(f\"{bert_model_name}/testing_results_unknown_labels.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"id":"06d00567","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.116125Z","iopub.status.idle":"2024-04-16T17:49:15.116589Z","shell.execute_reply":"2024-04-16T17:49:15.116362Z","shell.execute_reply.started":"2024-04-16T17:49:15.116344Z"},"papermill":{"duration":14.174761,"end_time":"2024-04-15T19:28:00.100426","exception":false,"start_time":"2024-04-15T19:27:45.925665","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!pip install data-science-utils"]},{"cell_type":"code","execution_count":null,"id":"538a27a1","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.118284Z","iopub.status.idle":"2024-04-16T17:49:15.118750Z","shell.execute_reply":"2024-04-16T17:49:15.118531Z","shell.execute_reply.started":"2024-04-16T17:49:15.118512Z"},"papermill":{"duration":1.267661,"end_time":"2024-04-15T19:28:01.759154","exception":false,"start_time":"2024-04-15T19:28:00.491493","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from ds_utils.metrics import plot_confusion_matrix\n","\n","plot_confusion_matrix(y_test_known_labels, predicted_labels_val, [1, 0])\n","pyplot.savefig(f\"{bert_model_name}/confusion_matrix.png\")\n","pyplot.show()"]},{"cell_type":"markdown","id":"cf385678","metadata":{"papermill":{"duration":0.375146,"end_time":"2024-04-15T19:28:02.560249","exception":false,"start_time":"2024-04-15T19:28:02.185103","status":"completed"},"tags":[]},"source":["# Saving the fine-tuned model\n","First let's save our model with the method ``save_pretrained``, then save our tokenizer with ``save_pretrained``.\n","\n","**Pay Attension**: tokenizer's ``save_pretrained`` need to get the path to save as a string.\n","\n","In reality, it is not required to run this cell. Obtaining the results is already enough. The saved model would be extremely heavy, and there are already fine tuned BERT models on HuggingFace"]},{"cell_type":"code","execution_count":null,"id":"fc0021e7","metadata":{"execution":{"iopub.status.busy":"2024-04-16T17:49:15.120278Z","iopub.status.idle":"2024-04-16T17:49:15.120733Z","shell.execute_reply":"2024-04-16T17:49:15.120522Z","shell.execute_reply.started":"2024-04-16T17:49:15.120503Z"},"papermill":{"duration":1.28376,"end_time":"2024-04-15T19:28:04.217720","exception":false,"start_time":"2024-04-15T19:28:02.933960","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from pathlib import Path\n","\n","output_dir = Path(\"__file__\").parents[0].absolute().joinpath(f\"{bert_model_name}/model_save\")\n","output_dir.mkdir(exist_ok=True)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","\n","# model_to_save = bert_classification_model.module if hasattr(bert_classification_model, 'module') else bert_classification_model  # Take care of distributed/parallel training\n","# model_to_save.save_pretrained(output_dir)\n","# tokenizer.save_pretrained(str(output_dir.absolute()))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4801042,"sourceId":8124328,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":3102.798711,"end_time":"2024-04-15T19:28:07.632117","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-15T18:36:24.833406","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"07f63ac385e245e69643261fa301d1e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a779e03f4ef4dfb9dc2d08b9d97ffa6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10ec51a0d39644c2bde1c044f4b0ebcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10fb04b92e174f849b69c56d203668ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a573658ed14c48d3a6a866cae319ac6c","IPY_MODEL_475ddaa2422245abb188229f13289e3b","IPY_MODEL_79acbae3e21e4376b30795092f52e8f2"],"layout":"IPY_MODEL_a13478a623724f66b1a14660d3ee9b4c"}},"128ec8e6c5d44978a2e9f175388e2f29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cb8161b6d734b6a8a15af28275ef483":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f84540677f046efa31d6d90bb798393":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21e35c6ec57b4193bf50aecf1f702ac0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"252f4288a4c84d728c963178e69ad1f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74ed9df4556f4ce7a213050c48d7c210","IPY_MODEL_bdb76a9b14d2447d942fd2620266531f","IPY_MODEL_42fd17a164ad42feb46d98ca2d4e9c71"],"layout":"IPY_MODEL_dc1cc80bd35b4d5dae4679b8825368f6"}},"2c93f0851b684e0494d3c01044488537":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3683cb285f2b4634ae9fd869432cc86c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"387cac20b6294c009cf4f1f1d9440597":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed790f27239244649065667c37f56eb8","placeholder":"​","style":"IPY_MODEL_3c973380efdc46cd8415b5809cfa7f77","value":"model.safetensors: 100%"}},"3c973380efdc46cd8415b5809cfa7f77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42fd17a164ad42feb46d98ca2d4e9c71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_740886dea1fa48a9a06c17dadf3b6fbd","placeholder":"​","style":"IPY_MODEL_c63272069adc4b46a5bcc989ea18c0e0","value":" 232k/232k [00:00&lt;00:00, 5.70MB/s]"}},"475ddaa2422245abb188229f13289e3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b6601cf17dd46be9c10f6e87a1144aa","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_128ec8e6c5d44978a2e9f175388e2f29","value":466062}},"48b48c0a4e764642a4baa3380c8a9a8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ab51461176848458df8f7aa1c18a9e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21e35c6ec57b4193bf50aecf1f702ac0","placeholder":"​","style":"IPY_MODEL_3683cb285f2b4634ae9fd869432cc86c","value":" 48.0/48.0 [00:00&lt;00:00, 3.54kB/s]"}},"5519dd8cd22445109116713dc5314117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55bbfc2baca942e7837c0d480dd8d6de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58395f0c6881462ab960c9756ad249c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5eb0fe60340413fb5161245a1a5096f","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5519dd8cd22445109116713dc5314117","value":48}},"5b6601cf17dd46be9c10f6e87a1144aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e3c797bc7a4829b0c8b2bec78b05bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"740886dea1fa48a9a06c17dadf3b6fbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74ed9df4556f4ce7a213050c48d7c210":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db671e831e74462a2edde8154c087b8","placeholder":"​","style":"IPY_MODEL_0a779e03f4ef4dfb9dc2d08b9d97ffa6","value":"vocab.txt: 100%"}},"79acbae3e21e4376b30795092f52e8f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c66320e4daa1422fb28121fd94b5668a","placeholder":"​","style":"IPY_MODEL_1f84540677f046efa31d6d90bb798393","value":" 466k/466k [00:00&lt;00:00, 22.4MB/s]"}},"7db671e831e74462a2edde8154c087b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b67ebaa10884aff89c4aafe648550d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb019431ea60438095147927a0935bbb","placeholder":"​","style":"IPY_MODEL_b7235bc7b1ce45658a992e230c300b7a","value":"tokenizer_config.json: 100%"}},"8f4c677ab169495581975dd1851e0edf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cb8161b6d734b6a8a15af28275ef483","placeholder":"​","style":"IPY_MODEL_70e3c797bc7a4829b0c8b2bec78b05bd","value":" 570/570 [00:00&lt;00:00, 47.9kB/s]"}},"8f4e34afb9cf4030977b9940bfa279e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db400aad92ad449eb08c29ad43c38774","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c814b40c830c4f61ba82b1da0edd6c05","value":440449768}},"98bce00eebcd4bcdba25e51e41dfdb15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9db693f375a0422f9d84b6e2fb9b63f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb031d76dbc14c88975b16a64c1cddea","placeholder":"​","style":"IPY_MODEL_2c93f0851b684e0494d3c01044488537","value":"config.json: 100%"}},"a13478a623724f66b1a14660d3ee9b4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4c828db3926417fa793da999dd17166":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a573658ed14c48d3a6a866cae319ac6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07f63ac385e245e69643261fa301d1e5","placeholder":"​","style":"IPY_MODEL_10ec51a0d39644c2bde1c044f4b0ebcf","value":"tokenizer.json: 100%"}},"a8b9dc282be24106806e603524f0e957":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2cb094195dd4c88b55eab4e7b32d99b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b67ebaa10884aff89c4aafe648550d8","IPY_MODEL_58395f0c6881462ab960c9756ad249c2","IPY_MODEL_4ab51461176848458df8f7aa1c18a9e7"],"layout":"IPY_MODEL_dc391f34db0e43ae96f1bc5079279edd"}},"b5ad6af9c7fb46e4a33bc078155a1fea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5ff972a4a0d452286e70738ffdf5ab6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9db693f375a0422f9d84b6e2fb9b63f1","IPY_MODEL_c6894eaf5ded4f9ab773f2b108874f37","IPY_MODEL_8f4c677ab169495581975dd1851e0edf"],"layout":"IPY_MODEL_48b48c0a4e764642a4baa3380c8a9a8e"}},"b7235bc7b1ce45658a992e230c300b7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdb76a9b14d2447d942fd2620266531f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6cac9b8ec2540d6a4acfead90020e91","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98bce00eebcd4bcdba25e51e41dfdb15","value":231508}},"c63272069adc4b46a5bcc989ea18c0e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c66320e4daa1422fb28121fd94b5668a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6894eaf5ded4f9ab773f2b108874f37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5ad6af9c7fb46e4a33bc078155a1fea","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef619ee29eca42038cd174dac32da185","value":570}},"c814b40c830c4f61ba82b1da0edd6c05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb031d76dbc14c88975b16a64c1cddea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7be6f8f41ca4f36a0e5beb3e49a1a1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b9dc282be24106806e603524f0e957","placeholder":"​","style":"IPY_MODEL_55bbfc2baca942e7837c0d480dd8d6de","value":" 440M/440M [00:02&lt;00:00, 201MB/s]"}},"db400aad92ad449eb08c29ad43c38774":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc1cc80bd35b4d5dae4679b8825368f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc391f34db0e43ae96f1bc5079279edd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5eb0fe60340413fb5161245a1a5096f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6cac9b8ec2540d6a4acfead90020e91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb019431ea60438095147927a0935bbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed790f27239244649065667c37f56eb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef619ee29eca42038cd174dac32da185":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3591226420045f883cad3c57057c3ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_387cac20b6294c009cf4f1f1d9440597","IPY_MODEL_8f4e34afb9cf4030977b9940bfa279e0","IPY_MODEL_d7be6f8f41ca4f36a0e5beb3e49a1a1e"],"layout":"IPY_MODEL_a4c828db3926417fa793da999dd17166"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}
